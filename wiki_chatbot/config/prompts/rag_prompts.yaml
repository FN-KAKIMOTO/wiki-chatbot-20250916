# RAG処理用プロンプト設定
# 検索・文書処理・要約などのRAG関連プロンプト

# === 検索クエリ拡張プロンプト ===
query_expansion:
  generic:
    name: "汎用クエリ拡張"
    system_prompt: |
      ユーザーの質問を分析し、関連する検索キーワードを生成してください。
      
      タスク:
      1. 元の質問から主要キーワードを抽出
      2. 同義語・関連語を追加
      3. 技術用語の英語・日本語両方を含める
      4. 検索精度向上のための追加キーワードを提案
      
      出力形式: キーワードを半角スペース区切りで出力
    
    user_prompt: |
      以下の質問について、検索に効果的なキーワードを生成してください:
      
      質問: {query}
      製品名: {product_name}

# === 文書チャンク化プロンプト ===
chunking:
  generic:
    name: "汎用文書チャンク化"
    system_prompt: |
      文書を適切なサイズのチャンクに分割してください。
      
      チャンク化の基準:
      1. 意味的なまとまりを保持
      2. 文脈が分断されないように配慮
      3. 見出し・セクションを考慮
      4. コードブロックは分割しない
      5. 表・図表は完全な形で保持
      
      各チャンクにはタイトル・要約を付けてください。
    
    user_prompt: |
      以下の文書を{chunk_size}文字以内のチャンクに分割してください:
      
      文書タイトル: {document_title}
      文書内容:
      {document_content}

# === 検索結果ランキング・フィルタリングプロンプト ===
result_ranking:
  generic:
    name: "汎用検索結果ランキング"
    system_prompt: |
      検索結果を質問に対する関連度で評価・ランキングしてください。
      
      評価基準:
      1. 質問への直接的な回答性 (40%)
      2. 情報の新しさ・正確性 (30%)
      3. 詳細度・完全性 (20%)
      4. 実用性・行動可能性 (10%)
      
      各結果に0-100のスコアを付けて、上位5件を選択してください。
    
    user_prompt: |
      質問: {query}
      製品: {product_name}
      
      検索結果を評価してください:
      {search_results}

# === 回答生成前処理プロンプト ===
context_preparation:
  generic:
    name: "汎用コンテキスト準備"
    system_prompt: |
      検索された複数の文書から、質問に答えるための最適なコンテキストを構築してください。
      
      処理内容:
      1. 重複情報の除去・統合
      2. 矛盾する情報の特定と注記
      3. 情報の時系列整理
      4. 関連度による優先順位付け
      5. 不足情報の特定
      
      出力: 構造化されたコンテキスト情報
    
    user_prompt: |
      質問: {query}
      製品: {product_name}
      
      以下の検索結果を統合してコンテキストを作成してください:
      {retrieved_documents}

# === 回答品質チェックプロンプト ===
answer_validation:
  generic:
    name: "汎用回答品質チェック"
    system_prompt: |
      生成された回答の品質をチェックし、改善提案を行ってください。
      
      チェック項目:
      1. 事実の正確性
      2. 情報源との整合性
      3. 回答の完全性
      4. 分かりやすさ
      5. 実用性
      
      問題がある場合は具体的な修正案を提案してください。
    
    user_prompt: |
      質問: {query}
      生成された回答: {generated_answer}
      情報源: {source_documents}
      
      この回答の品質を評価し、必要に応じて改善案を提示してください。

# === 要約生成プロンプト ===
summarization:
  generic:
    name: "汎用要約生成"
    system_prompt: |
      文書の要約を生成してください。
      
      要約の要件:
      1. 重要なポイントを漏らさない
      2. 簡潔で理解しやすい
      3. 階層構造を保持
      4. 数値・固有名詞は正確に
      5. アクションアイテムがあれば明記
      
      要約レベル: {summary_level} (brief/moderate/detailed)
    
    user_prompt: |
      以下の文書を{summary_length}文字以内で要約してください:
      
      文書: {document_content}
      対象読者: {target_audience}

# === メタデータ抽出プロンプト ===
metadata_extraction:
  generic:
    name: "汎用メタデータ抽出"
    system_prompt: |
      文書からメタデータを抽出してください。
      
      抽出項目:
      - タイトル・見出し
      - 作成日・更新日
      - 著者・担当部署
      - 文書種別・カテゴリ
      - キーワード・タグ
      - 対象読者・権限レベル
      - 関連文書
      
      JSON形式で出力してください。
    
    user_prompt: |
      以下の文書からメタデータを抽出してください:
      
      文書: {document_content}
      ファイル名: {filename}

# === 類似文書検索プロンプト ===
similar_documents:
  generic:
    name: "汎用類似文書検索"
    system_prompt: |
      指定された文書と類似する文書を特定してください。
      
      類似性の基準:
      1. トピック・テーマの一致
      2. 対象読者の共通性
      3. 内容レベルの近さ
      4. 更新頻度・重要度
      
      類似度スコア(0-100)と理由を含めて回答してください。
    
    user_prompt: |
      基準文書: {reference_document}
      
      以下の候補文書との類似度を評価してください:
      {candidate_documents}

# === エラー処理・フォールバックプロンプト ===
fallback_response:
  generic:
    name: "汎用フォールバック応答"
    system_prompt: |
      適切な回答が見つからない場合の代替応答を生成してください。
      
      フォールバック応答の要件:
      1. 状況を正直に説明
      2. 代替手段・リソースを提案
      3. 問い合わせ先を案内
      4. 関連する可能性のある情報を提示
      5. 丁寧で建設的な対応
    
    user_prompt: |
      質問: {query}
      製品: {product_name}
      状況: {error_context}
      
      適切なフォールバック応答を生成してください。