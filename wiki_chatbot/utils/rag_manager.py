import os
import json
import hashlib
from typing import List, Dict, Any, Optional
import pandas as pd
import chromadb
from chromadb.config import Settings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PyPDFLoader, TextLoader
from langchain_openai import OpenAIEmbeddings
from docx import Document
import streamlit as st


class RAGManager:
    _chroma_client = None
    _chroma_settings = None
    _chroma_dir = None

    def __init__(self, data_dir: str = "data"):
        self.data_dir = data_dir
        self.chroma_dir = os.path.join(data_dir, "chroma_db")
        os.makedirs(self.chroma_dir, exist_ok=True)

        # ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²å™¨ã®åˆæœŸåŒ–ï¼ˆæœ€åˆã«å®Ÿè¡Œï¼‰
        self.text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)

        # åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
        try:
            self.embeddings = OpenAIEmbeddings()
        except Exception as e:
            st.warning("OpenAI API key not set. Using default embeddings.")
            self.embeddings = None

        # ChromaDBã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ï¼ˆã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
        self.client = None
        self.chroma_available = False

        # ã‚¯ãƒ©ã‚¹å¤‰æ•°ã¨ã—ã¦åŒã˜è¨­å®šã‚’å…±æœ‰
        if RAGManager._chroma_dir != self.chroma_dir or RAGManager._chroma_client is None:
            self._initialize_chroma_client()
        else:
            # æ—¢å­˜ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å†åˆ©ç”¨
            self.client = RAGManager._chroma_client
            self.chroma_available = self.client is not None

    def _initialize_chroma_client(self):
        """ChromaDBã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–"""
        try:
            # æ—¢å­˜ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒã‚ã‚‹å ´åˆã¯ãƒªã‚»ãƒƒãƒˆ
            if RAGManager._chroma_client is not None:
                try:
                    RAGManager._chroma_client = None
                except Exception:
                    pass

            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ¨©é™ã‚’ç¢ºå®Ÿã«è¨­å®š
            try:
                os.chmod(self.chroma_dir, 0o755)
                for root, dirs, files in os.walk(self.chroma_dir):
                    for d in dirs:
                        os.chmod(os.path.join(root, d), 0o755)
                    for f in files:
                        os.chmod(os.path.join(root, f), 0o644)
            except Exception:
                pass  # æ¨©é™è¨­å®šã«å¤±æ•—ã—ã¦ã‚‚ç¶šè¡Œ

            # ChromaDBè¨­å®šï¼ˆreadonlyå¯¾ç­–ï¼‰
            settings = Settings(
                allow_reset=True,
                anonymized_telemetry=False
            )

            RAGManager._chroma_settings = settings
            RAGManager._chroma_dir = self.chroma_dir
            RAGManager._chroma_client = chromadb.PersistentClient(path=self.chroma_dir, settings=settings)

            self.client = RAGManager._chroma_client
            self.chroma_available = True
        except Exception as chroma_error:
            error_msg = str(chroma_error)

            # å„ç¨®ã‚¨ãƒ©ãƒ¼ã«å¯¾å¿œã—ãŸè‡ªå‹•å¾©æ—§
            if ("readonly database" in error_msg or
                "no such table: databases" in error_msg or
                "database is locked" in error_msg or
                "already exists" in error_msg or
                "different settings" in error_msg):
                st.warning("ðŸ”„ ChromaDBãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å†åˆæœŸåŒ–ã—ã¦ã„ã¾ã™...")
                import shutil
                if os.path.exists(self.chroma_dir):
                    shutil.rmtree(self.chroma_dir)
                os.makedirs(self.chroma_dir, exist_ok=True)

                # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ¨©é™ã‚’ç¢ºå®Ÿã«è¨­å®š
                try:
                    os.chmod(self.chroma_dir, 0o755)
                except Exception:
                    pass

                try:
                    settings = Settings(
                        allow_reset=True,
                        anonymized_telemetry=False
                    )
                    self.client = chromadb.PersistentClient(path=self.chroma_dir, settings=settings)
                    self.chroma_available = True
                    st.success("âœ… ChromaDB ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒæ­£å¸¸ã«å†åˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸ")
                except Exception:
                    st.error("âš ï¸ ChromaDBå†åˆæœŸåŒ–ã«å¤±æ•—: RAGæ©Ÿèƒ½ã¯ç„¡åŠ¹ã«ãªã‚Šã¾ã™")
                    self.client = None
                    self.chroma_available = False
            else:
                st.error(f"âš ï¸ ChromaDBåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {error_msg}")
                st.error("RAGæ©Ÿèƒ½ã¯ç„¡åŠ¹ã«ãªã‚Šã¾ã™")
                self.client = None
                self.chroma_available = False



    def get_or_create_collection(self, product_name: str):
        if not self.chroma_available:
            st.error("âŒ ChromaDB ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return None

        collection_name = f"product_{product_name.lower().replace(' ', '_')}"
        try:
            collection = self.client.get_collection(name=collection_name)
            if st.secrets.get("DEBUG_MODE", False):
                st.success(f"âœ… æ—¢å­˜ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å–å¾—: {collection_name}")
        except Exception as get_error:
            get_error_msg = str(get_error)

            # readonly ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯å†åˆæœŸåŒ–ã‚’è©¦è¡Œ
            if "readonly database" in get_error_msg or "database is locked" in get_error_msg:
                st.warning("ðŸ”„ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼ã€å†åˆæœŸåŒ–ã‚’è©¦è¡Œ...")
                self._reinitialize_chroma()
                if not self.chroma_available:
                    return None

            try:
                collection = self.client.create_collection(name=collection_name, metadata={"hnsw:space": "cosine"})
                if st.secrets.get("DEBUG_MODE", False):
                    st.success(f"âœ… æ–°è¦ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆ: {collection_name}")
            except Exception as create_error:
                create_error_msg = str(create_error)

                # readonly ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯å†åˆæœŸåŒ–ã‚’è©¦è¡Œ
                if "readonly database" in create_error_msg or "database is locked" in create_error_msg:
                    st.warning("ðŸ”„ ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆã§ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼ã€å†åˆæœŸåŒ–ã‚’è©¦è¡Œ...")
                    self._reinitialize_chroma()
                    if not self.chroma_available:
                        return None

                    # å†åˆæœŸåŒ–å¾Œã«å†è©¦è¡Œ
                    try:
                        collection = self.client.create_collection(name=collection_name, metadata={"hnsw:space": "cosine"})
                        if st.secrets.get("DEBUG_MODE", False):
                            st.success(f"âœ… å†åˆæœŸåŒ–å¾Œã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆæˆåŠŸ: {collection_name}")
                    except Exception:
                        st.error(f"âŒ å†åˆæœŸåŒ–å¾Œã‚‚ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆå¤±æ•—: {collection_name}")
                        return None
                else:
                    st.error(f"âŒ ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆå¤±æ•—: {collection_name}")
                    st.error(f"å–å¾—ã‚¨ãƒ©ãƒ¼: {get_error}")
                    st.error(f"ä½œæˆã‚¨ãƒ©ãƒ¼: {create_error}")
                    return None

        return collection

    def _reinitialize_chroma(self):
        """ChromaDBã®å†åˆæœŸåŒ–"""
        try:
            # æ—¢å­˜ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ã‚¯ãƒªã‚¢
            RAGManager._chroma_client = None

            import shutil
            if os.path.exists(self.chroma_dir):
                shutil.rmtree(self.chroma_dir)
            os.makedirs(self.chroma_dir, exist_ok=True)

            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ¨©é™ã‚’è¨­å®š
            try:
                os.chmod(self.chroma_dir, 0o755)
            except Exception:
                pass

            # æ–°ã—ã„ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
            settings = Settings(
                allow_reset=True,
                anonymized_telemetry=False
            )

            RAGManager._chroma_settings = settings
            RAGManager._chroma_dir = self.chroma_dir
            RAGManager._chroma_client = chromadb.PersistentClient(path=self.chroma_dir, settings=settings)

            self.client = RAGManager._chroma_client
            self.chroma_available = True
            st.info("âœ… ChromaDBå†åˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            st.error(f"âŒ ChromaDBå†åˆæœŸåŒ–å¤±æ•—: {e}")
            RAGManager._chroma_client = None
            self.client = None
            self.chroma_available = False

    def get_file_hash(self, file_content: bytes) -> str:
        return hashlib.md5(file_content).hexdigest()

    def _is_duplicate_file(self, product_name: str, file_hash: str) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚·ãƒ¥ã«ã‚ˆã‚‹é‡è¤‡ãƒã‚§ãƒƒã‚¯"""
        if not self.chroma_available:
            return False

        try:
            collection = self.get_or_create_collection(product_name)
            if collection is None:
                return False

            results = collection.get(where={"file_hash": file_hash})
            return bool(results and results["ids"])
        except Exception:
            return False

    def extract_text_from_file(self, file_path: str, file_type: str) -> str:
        try:
            if file_type == "txt":
                with open(file_path, "r", encoding="utf-8") as f:
                    return f.read()
            elif file_type == "pdf":
                loader = PyPDFLoader(file_path)
                documents = loader.load()
                return "\n".join([doc.page_content for doc in documents])
            elif file_type == "docx":
                doc = Document(file_path)
                return "\n".join([paragraph.text for paragraph in doc.paragraphs])
            elif file_type == "pptx":
                from pptx import Presentation

                prs = Presentation(file_path)
                text_content = []

                for slide_num, slide in enumerate(prs.slides, 1):
                    slide_text = f"=== ã‚¹ãƒ©ã‚¤ãƒ‰ {slide_num} ===\n"

                    for shape in slide.shapes:
                        if hasattr(shape, "text") and shape.text.strip():
                            slide_text += shape.text.strip() + "\n"

                        # è¡¨ãŒã‚ã‚‹å ´åˆã®å‡¦ç†
                        if hasattr(shape, "table"):
                            table = shape.table
                            for row in table.rows:
                                row_text = " | ".join([cell.text.strip() for cell in row.cells])
                                slide_text += row_text + "\n"

                    text_content.append(slide_text)

                return "\n\n".join(text_content)
            elif file_type == "html":
                with open(file_path, "r", encoding="utf-8") as f:
                    content = f.read()
                from bs4 import BeautifulSoup

                soup = BeautifulSoup(content, "html.parser")
                return soup.get_text()
            elif file_type == "csv":
                df = pd.read_csv(file_path)

                # CSVã®å„è¡Œã‚’Q&Aå½¢å¼ã¨ã—ã¦å‡¦ç†
                qa_pairs = []

                # åˆ—æ•°ã‚’ãƒã‚§ãƒƒã‚¯
                if len(df.columns) >= 2:
                    # 2åˆ—ä»¥ä¸Šã®å ´åˆã€æœ€åˆã®åˆ—ã‚’è³ªå•ã€2ç•ªç›®ã®åˆ—ã‚’å›žç­”ã¨ã—ã¦å‡¦ç†
                    # 3åˆ—ç›®ã¯å‚ç…§ãƒ‡ãƒ¼ã‚¿ï¼ˆRAGå‡¦ç†ã«ã¯å«ã‚ãªã„ï¼‰
                    question_col = df.columns[0]
                    answer_col = df.columns[1]

                    for index, row in df.iterrows():
                        question = str(row[question_col]).strip()
                        answer = str(row[answer_col]).strip()

                        if question and answer and question != "nan" and answer != "nan":
                            # å‚ç…§ãƒ‡ãƒ¼ã‚¿ã¯RAGå‡¦ç†ã«å«ã‚ãªã„
                            qa_text = f"è³ªå•: {question}\nå›žç­”: {answer}"
                            qa_pairs.append(qa_text)
                else:
                    # 1åˆ—ã®å ´åˆã¯å¾“æ¥é€šã‚Šã®å‡¦ç†
                    return df.to_string()

                return "\n\n".join(qa_pairs) if qa_pairs else df.to_string()
            else:
                return ""
        except Exception as e:
            st.error(f"Error reading file: {e}")
            return ""

    def add_csv_as_qa_pairs(self, product_name: str, file_name: str, file_content: bytes) -> bool:
        """CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å„è¡Œã‚’å€‹åˆ¥ã®Q&Aãƒšã‚¢ã¨ã—ã¦å‡¦ç†"""
        if not self.chroma_available:
            st.error("âŒ ChromaDB ãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½åŠ ã§ãã¾ã›ã‚“")
            st.error("ðŸ’¡ ã‚¢ãƒ—ãƒªã‚’å†èµ·å‹•ã—ã¦ãã ã•ã„")
            return False

        try:
            collection = self.get_or_create_collection(product_name)
            if collection is None:
                st.error(f"âŒ å•†æã€Œ{product_name}ã€ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
                return False

            file_hash = self.get_file_hash(file_content)

            # é‡è¤‡ãƒã‚§ãƒƒã‚¯
            if self._is_duplicate_file(product_name, file_hash):
                st.warning(f"âš ï¸ CSVãƒ•ã‚¡ã‚¤ãƒ«ã€Œ{file_name}ã€ã¯æ—¢ã«è¿½åŠ ã•ã‚Œã¦ã„ã¾ã™ï¼ˆé‡è¤‡ã‚¹ã‚­ãƒƒãƒ—ï¼‰")
                return True

            temp_file_path = os.path.join(self.data_dir, f"temp_{file_hash}.csv")
            with open(temp_file_path, "wb") as f:
                f.write(file_content)

            df = pd.read_csv(temp_file_path)

            if len(df.columns) >= 2:
                # ã‚«ãƒ©ãƒ åã‚’æ¤œè¨¼ã—ã¦é©åˆ‡ã«è¨­å®šï¼ˆé¡žä¼¼èªžã‚‚æ¤œå‡ºï¼‰
                def find_column_by_keywords(columns, keywords):
                    """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆã‹ã‚‰ã‚«ãƒ©ãƒ ã‚’æ¤œç´¢"""
                    for col in columns:
                        if any(keyword in str(col).lower() for keyword in keywords):
                            return col
                    return None

                # ã‚«ãƒ©ãƒ å€™è£œã®å®šç¾©
                question_keywords = ["è³ªå•", "question", "q", "å•", "å•ã„"]
                answer_keywords = ["å›žç­”", "ç­”ãˆ", "answer", "a", "å¿œç­”", "å›ž"]
                reference_keywords = ["å‚è€ƒ", "å‚ç…§", "reference", "ref", "ãƒªãƒ³ã‚¯", "link", "url", "å‡ºå…¸"]

                # å„ã‚«ãƒ©ãƒ ã‚’æ¤œç´¢
                question_col = find_column_by_keywords(df.columns, question_keywords)
                answer_col = find_column_by_keywords(df.columns, answer_keywords)
                reference_col = find_column_by_keywords(df.columns, reference_keywords)

                # è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ä½ç½®ãƒ™ãƒ¼ã‚¹ã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                if not question_col:
                    question_col = df.columns[0]
                if not answer_col:
                    answer_col = df.columns[1]
                if not reference_col and len(df.columns) >= 3:
                    reference_col = df.columns[2]

                # ãƒ‡ãƒãƒƒã‚°æƒ…å ±è¡¨ç¤º
                if st.secrets.get("DEBUG_MODE", False):
                    st.write(f"ðŸ” **CSV ã‚«ãƒ©ãƒ è‡ªå‹•æ¤œå‡ºçµæžœ**:")
                    st.write(f"- æ¤œå‡ºã•ã‚ŒãŸã‚«ãƒ©ãƒ : {list(df.columns)}")
                    st.write(f"- è³ªå•ã‚«ãƒ©ãƒ : '{question_col}'")
                    st.write(f"- å›žç­”ã‚«ãƒ©ãƒ : '{answer_col}'")
                    st.write(f"- å‚ç…§ã‚«ãƒ©ãƒ : '{reference_col}'")

                qa_count = 0
                for index, row in df.iterrows():
                    question = str(row[question_col]).strip()
                    answer = str(row[answer_col]).strip()

                    if question and answer and question != "nan" and answer != "nan":
                        # RAGå‡¦ç†ç”¨ãƒ†ã‚­ã‚¹ãƒˆï¼ˆå‚ç…§ãƒ‡ãƒ¼ã‚¿ã¯å«ã‚ãªã„ï¼‰
                        qa_text = f"è³ªå•: {question}\nå›žç­”: {answer}"
                        doc_id = f"{file_hash}_qa_{index}"

                        # å‚ç…§ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ï¼ˆã‚ã‚Œã°ï¼‰
                        reference_data = ""
                        if reference_col and pd.notna(row[reference_col]):
                            reference_data = str(row[reference_col]).strip()

                        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«å‚ç…§ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ï¼ˆæ¤œç´¢çµæžœè¡¨ç¤ºç”¨ï¼‰
                        metadata = {
                            "file_name": file_name,
                            "file_hash": file_hash,
                            "qa_index": index,
                            "product": product_name,
                            "question": question,
                            "answer": answer,
                            "type": "qa_pair",
                        }

                        # å‚ç…§ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿è¿½åŠ 
                        if reference_data:
                            metadata["reference"] = reference_data

                        try:
                            collection.add(
                                documents=[qa_text],  # å‚ç…§ãƒ‡ãƒ¼ã‚¿ã¯RAGå‡¦ç†ã«å«ã‚ãªã„
                                metadatas=[metadata],
                                ids=[doc_id],
                            )
                        except Exception as add_error:
                            if "readonly database" in str(add_error) or "database is locked" in str(add_error):
                                st.warning("ðŸ”„ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã€å†åˆæœŸåŒ–ã—ã¦å†è©¦è¡Œ...")
                                self._reinitialize_chroma()
                                collection = self.get_or_create_collection(product_name)
                                if collection:
                                    collection.add(
                                        documents=[qa_text],
                                        metadatas=[metadata],
                                        ids=[doc_id],
                                    )
                            else:
                                raise add_error
                        qa_count += 1

                os.remove(temp_file_path)
                # å‚ç…§ãƒ‡ãƒ¼ã‚¿ä»˜ãã®ä»¶æ•°ã‚‚è¡¨ç¤º
                reference_count = sum(1 for _, row in df.iterrows()
                                    if reference_col and pd.notna(row[reference_col]) and str(row[reference_col]).strip())

                # è©³ç´°ãªã‚µãƒžãƒªãƒ¼æƒ…å ±ã‚’è¡¨ç¤º
                if st.secrets.get("DEBUG_MODE", False):
                    st.write(f"ðŸ” **CSVå‡¦ç†ã‚µãƒžãƒªãƒ¼**: {file_name}")
                    st.write(f"- æ¤œå‡ºã‚«ãƒ©ãƒ : {list(df.columns)}")
                    st.write(f"- ä½¿ç”¨ã‚«ãƒ©ãƒ : è³ªå•='{question_col}', å›žç­”='{answer_col}', å‚ç…§='{reference_col}'")
                    st.write(f"- ç·è¡Œæ•°: {len(df)}, å‡¦ç†æ¸ˆã¿: {qa_count}")

                if reference_count > 0:
                    st.success(f"âœ… {qa_count}çµ„ã®Q&Aãƒšã‚¢ï¼ˆã†ã¡{reference_count}ä»¶ã¯å‚ç…§ãƒ‡ãƒ¼ã‚¿ä»˜ãï¼‰ã‚’è¿½åŠ ã—ã¾ã—ãŸ")
                else:
                    st.success(f"âœ… {qa_count}çµ„ã®Q&Aãƒšã‚¢ã‚’è¿½åŠ ã—ã¾ã—ãŸ")
                return True
            else:
                st.error("CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯è³ªå•ã¨å›žç­”ã®2åˆ—ãŒå¿…è¦ã§ã™")
                os.remove(temp_file_path)
                return False

        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if 'temp_file_path' in locals() and os.path.exists(temp_file_path):
                os.remove(temp_file_path)
            st.error(f"âŒ CSVå‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False

    def add_document(self, product_name: str, file_name: str, file_content: bytes, file_type: str) -> bool:
        if not self.chroma_available:
            st.error("âŒ ChromaDB ãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½åŠ ã§ãã¾ã›ã‚“")
            st.error("ðŸ’¡ ã‚¢ãƒ—ãƒªã‚’å†èµ·å‹•ã—ã¦ãã ã•ã„")
            return False

        try:
            collection = self.get_or_create_collection(product_name)
            if collection is None:
                st.error(f"âŒ å•†æã€Œ{product_name}ã€ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
                return False

            file_hash = self.get_file_hash(file_content)

            # é‡è¤‡ãƒã‚§ãƒƒã‚¯
            if self._is_duplicate_file(product_name, file_hash):
                st.warning(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ã€Œ{file_name}ã€ã¯æ—¢ã«è¿½åŠ ã•ã‚Œã¦ã„ã¾ã™ï¼ˆé‡è¤‡ã‚¹ã‚­ãƒƒãƒ—ï¼‰")
                return True

            temp_file_path = os.path.join(self.data_dir, f"temp_{file_hash}.{file_type}")
            with open(temp_file_path, "wb") as f:
                f.write(file_content)

            text_content = self.extract_text_from_file(temp_file_path, file_type)

            if not text_content or not text_content.strip():
                st.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã€Œ{file_name}ã€ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
                os.remove(temp_file_path)
                return False

            if text_content:
                chunks = self.text_splitter.split_text(text_content)

                if st.secrets.get("DEBUG_MODE", False):
                    st.info(f"ðŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†: {file_name}")
                    st.info(f"ðŸ“Š ãƒ†ã‚­ã‚¹ãƒˆé•·: {len(text_content)}æ–‡å­—")
                    st.info(f"ðŸ§© ãƒãƒ£ãƒ³ã‚¯æ•°: {len(chunks)}å€‹")

                for i, chunk in enumerate(chunks):
                    doc_id = f"{file_hash}_{i}"
                    try:
                        collection.add(
                            documents=[chunk],
                            metadatas=[
                                {"file_name": file_name, "file_hash": file_hash, "chunk_index": i, "product": product_name}
                            ],
                            ids=[doc_id],
                        )
                    except Exception as add_error:
                        if "readonly database" in str(add_error) or "database is locked" in str(add_error):
                            st.warning("ðŸ”„ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã€å†åˆæœŸåŒ–ã—ã¦å†è©¦è¡Œ...")
                            self._reinitialize_chroma()
                            collection = self.get_or_create_collection(product_name)
                            if collection:
                                collection.add(
                                    documents=[chunk],
                                    metadatas=[
                                        {"file_name": file_name, "file_hash": file_hash, "chunk_index": i, "product": product_name}
                                    ],
                                    ids=[doc_id],
                                )
                        else:
                            raise add_error

                if st.secrets.get("DEBUG_MODE", False):
                    st.success(f"âœ… {len(chunks)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ChromeDBã«è¿½åŠ å®Œäº†")

            os.remove(temp_file_path)
            return True

        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if 'temp_file_path' in locals() and os.path.exists(temp_file_path):
                os.remove(temp_file_path)
            st.error(f"âŒ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¿½åŠ ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def remove_document(self, product_name: str, file_name: str) -> bool:
        if not self.chroma_available:
            st.error("âŒ ChromaDB ãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã§ãã¾ã›ã‚“")
            return False

        try:
            collection = self.get_or_create_collection(product_name)
            if collection is None:
                return False

            results = collection.get(where={"file_name": file_name})

            if results and results["ids"]:
                try:
                    collection.delete(ids=results["ids"])
                    return True
                except Exception as delete_error:
                    if "readonly database" in str(delete_error) or "database is locked" in str(delete_error):
                        st.warning("ðŸ”„ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã€å†åˆæœŸåŒ–ã—ã¦å†è©¦è¡Œ...")
                        self._reinitialize_chroma()
                        collection = self.get_or_create_collection(product_name)
                        if collection:
                            results = collection.get(where={"file_name": file_name})
                            if results and results["ids"]:
                                collection.delete(ids=results["ids"])
                                return True
                    else:
                        raise delete_error
            return False

        except Exception as e:
            st.error(f"Error removing document: {e}")
            return False

    def search(self, product_name: str, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        if not self.chroma_available:
            return []

        try:
            collection = self.get_or_create_collection(product_name)
            if collection is None:
                return []

            results = collection.query(query_texts=[query], n_results=top_k)

            search_results = []
            if results["documents"] and results["documents"][0]:
                for i in range(len(results["documents"][0])):
                    distance = results["distances"][0][i] if results["distances"] else 0.0

                    # ChromaDBã¯ cosine_distance = 1.0 - cosine_similarity ã‚’è¿”ã™
                    # ã—ãŸãŒã£ã¦ cosine_similarity = 1.0 - cosine_distance
                    cosine_similarity = 1.0 - distance

                    # æ•°å€¤ç²¾åº¦ã®å•é¡Œã§è² ã«ãªã‚‹å¯èƒ½æ€§ã‚’è€ƒæ…®ï¼ˆå®Ÿéš›ã¯ç¨€ï¼‰
                    similarity_score = max(0.0, min(1.0, cosine_similarity))

                    search_results.append(
                        {
                            "content": results["documents"][0][i],
                            "metadata": results["metadatas"][0][i] if results["metadatas"] else {},
                            "distance": distance,
                            "similarity_score": similarity_score,
                        }
                    )

            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’å‡ºåŠ›ï¼ˆé–‹ç™ºæ™‚ã®ã¿ï¼‰
            if st.secrets.get("DEBUG_MODE", False):
                st.write(f"ðŸ” æ¤œç´¢ã‚¯ã‚¨ãƒª: '{query}' (ä¸Šä½{len(search_results)}ä»¶)")
                st.write("**ChromaDBè¨ˆç®—å¼**: cosine_similarity = 1.0 - cosine_distance")

                for i, result in enumerate(search_results[:3]):
                    distance = result['distance']
                    similarity = result['similarity_score']
                    cosine_sim_check = 1.0 - distance
                    st.write(f"çµæžœ{i+1}: è·é›¢={distance:.4f}, é¡žä¼¼åº¦={similarity:.4f} (æ¤œç®—: {cosine_sim_check:.4f})")
                    st.write(f"å†…å®¹: {result['content'][:100]}...")

                # ã‚½ãƒ¼ãƒˆå‰å¾Œã®é †åºç¢ºèª
                if len(search_results) > 1:
                    distances = [r['distance'] for r in search_results]
                    is_sorted = all(distances[i] <= distances[i+1] for i in range(len(distances)-1))
                    st.write(f"ðŸ“Š ChromaDBçµæžœã‚½ãƒ¼ãƒˆçŠ¶æ³: {'âœ… æ—¢ã«ã‚½ãƒ¼ãƒˆæ¸ˆã¿' if is_sorted else 'âŒ ã‚½ãƒ¼ãƒˆãŒå¿…è¦'}")

                # è·é›¢ã¨é¡žä¼¼åº¦ã®ç¯„å›²ç¢ºèª
                min_dist, max_dist = min(distances), max(distances)
                min_sim = min(r['similarity_score'] for r in search_results)
                max_sim = max(r['similarity_score'] for r in search_results)
                st.write(f"ðŸ“Š ç¯„å›²ç¢ºèª: è·é›¢=[{min_dist:.4f}, {max_dist:.4f}], é¡žä¼¼åº¦=[{min_sim:.4f}, {max_sim:.4f}]")

            # ChromaDBã¯æ—¢ã«è·é›¢é †ï¼ˆå°ã•ã„é †ï¼‰ã§è¿”ã™ãŒã€å¿µã®ãŸã‚æ˜Žç¤ºçš„ã«ã‚½ãƒ¼ãƒˆ
            search_results.sort(key=lambda x: x["distance"])

            # é–¢é€£åº¦ã®ä½Žã„çµæžœã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            similarity_threshold = 0.7  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            try:
                # ç¾åœ¨ã®RAGè¨­å®šã‹ã‚‰é–¾å€¤ã‚’å–å¾—
                _, rag_config = get_current_rag_config()
                similarity_threshold = getattr(rag_config, 'similarity_threshold', 0.7)
            except Exception as e:
                # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰æ™‚ã®ã¿ã‚¨ãƒ©ãƒ¼è¡¨ç¤º
                if st.secrets.get("DEBUG_MODE", False):
                    st.warning(f"RAGè¨­å®šå–å¾—ã‚¨ãƒ©ãƒ¼ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤0.7ã‚’ä½¿ç”¨): {e}")
                similarity_threshold = 0.7

            # é¡žä¼¼åº¦ãŒé–¾å€¤ä»¥ä¸Šã®ã‚‚ã®ã‚’ä¿æŒï¼ˆã‚ˆã‚Šç›´æ„Ÿçš„ï¼‰
            filtered_results = [r for r in search_results if r["similarity_score"] >= similarity_threshold]

            if st.secrets.get("DEBUG_MODE", False) and len(filtered_results) < len(search_results):
                st.write(f"âš ï¸ é–¢é€£åº¦ã®ä½Žã„çµæžœã‚’ {len(search_results) - len(filtered_results)} ä»¶é™¤å¤–ã—ã¾ã—ãŸ")

            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®çµæžœå‡¦ç†
            if filtered_results:
                return filtered_results
            elif search_results:
                # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œã«çµæžœãŒãªã„å ´åˆã€æœ€ã‚‚é–¢é€£åº¦ã®é«˜ã„1ä»¶ã‚’è¿”ã™
                if st.secrets.get("DEBUG_MODE", False):
                    st.warning(f"å…¨çµæžœãŒé–¾å€¤({similarity_threshold})ã‚’ä¸‹å›žã‚Šã¾ã—ãŸã€‚æœ€é«˜ã‚¹ã‚³ã‚¢çµæžœã‚’è¿”ã—ã¾ã™ã€‚")
                return search_results[:1]
            else:
                return []

        except Exception as e:
            st.error(f"Error searching: {e}")
            return []

    def list_documents(self, product_name: str) -> List[str]:
        if not self.chroma_available:
            return []

        try:
            collection = self.get_or_create_collection(product_name)
            if collection is None:
                return []
            results = collection.get()

            if results and results["metadatas"]:
                file_names = set()
                for metadata in results["metadatas"]:
                    if "file_name" in metadata:
                        file_names.add(metadata["file_name"])
                return list(file_names)
            return []

        except Exception as e:
            st.error(f"Error listing documents: {e}")
            return []

    def list_products(self) -> List[str]:
        if not self.chroma_available:
            return []

        try:
            collections = self.client.list_collections()
            products = []
            for collection in collections:
                if collection.name.startswith("product_"):
                    product_name = collection.name.replace("product_", "").replace("_", " ").title()
                    products.append(product_name)
            return products
        except Exception as e:
            st.error(f"Error listing products: {e}")
            return []
