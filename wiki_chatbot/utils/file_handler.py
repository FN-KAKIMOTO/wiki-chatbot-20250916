import streamlit as st
import tempfile
import os
import pandas as pd
import io
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse
from typing import List, Dict, Any
from .rag_manager import RAGManager
from .feedback_manager import feedback_manager


class FileHandler:
    def __init__(self):
        self.rag_manager = RAGManager()
        self.supported_extensions = {
            "txt": "text/plain",
            "pdf": "application/pdf",
            "docx": "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            "pptx": "application/vnd.openxmlformats-officedocument.presentationml.presentation",
            "html": "text/html",
            "csv": "text/csv",
        }

    def get_file_type(self, filename: str) -> str:
        return filename.split(".")[-1].lower() if "." in filename else ""

    def is_supported_file(self, filename: str) -> bool:
        file_type = self.get_file_type(filename)
        return file_type in self.supported_extensions

    def fetch_html_body(self, url: str) -> str:
        """URLã‹ã‚‰HTMLã‚’å–å¾—ã—ã¦bodyãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
        try:
            # URLã®æ­£è¦åŒ–
            if not url.startswith(('http://', 'https://')):
                url = 'https://' + url

            # HTMLã‚’å–å¾—
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            response = requests.get(url, headers=headers, timeout=30)
            response.raise_for_status()

            # BeautifulSoupã§HTMLã‚’è§£æ
            soup = BeautifulSoup(response.content, 'html.parser')

            # ä¸è¦ãªè¦ç´ ã‚’å‰Šé™¤
            for element in soup.find_all(['script', 'style', 'nav', 'header', 'footer', 'aside']):
                element.decompose()

            # bodyã‚¿ã‚°ã‹ã‚‰æœ¬æ–‡ã‚’æŠ½å‡º
            body = soup.find('body')
            if body:
                text = body.get_text(separator='\n', strip=True)
            else:
                text = soup.get_text(separator='\n', strip=True)

            # ç©ºç™½è¡Œã‚’æ•´ç†
            lines = [line.strip() for line in text.split('\n') if line.strip()]
            return '\n'.join(lines)

        except requests.RequestException as e:
            return f"URLå–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}"
        except Exception as e:
            return f"HTMLè§£æã‚¨ãƒ©ãƒ¼: {str(e)}"

    def process_url_csv(self, product_name: str, csv_content: bytes) -> Dict[str, Any]:
        """URLãŒè¨˜è¼‰ã•ã‚ŒãŸCSVã‚’å‡¦ç†ã—ã¦HTMLã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’RAGã«è¿½åŠ """
        try:
            # CSVã‚’èª­ã¿è¾¼ã¿
            df = pd.read_csv(io.BytesIO(csv_content), encoding='utf-8')

            # URLã‚’å«ã‚€åˆ—ã‚’ç‰¹å®š
            url_columns = []
            for col in df.columns:
                if any(keyword in col.lower() for keyword in ['url', 'link', 'ãƒªãƒ³ã‚¯', 'ãƒšãƒ¼ã‚¸', 'ã‚µã‚¤ãƒˆ']):
                    url_columns.append(col)

            if not url_columns:
                # URLã£ã½ã„å€¤ã‚’å«ã‚€åˆ—ã‚’è‡ªå‹•æ¤œå‡º
                for col in df.columns:
                    sample_values = df[col].dropna().astype(str).head(5)
                    if any('http' in str(val) or '.' in str(val) for val in sample_values):
                        url_columns.append(col)

            if not url_columns:
                return {"success": False, "error": "URLåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}

            results = {
                "success": True,
                "processed_urls": 0,
                "failed_urls": 0,
                "error_details": []
            }

            # å„URLã‚’å‡¦ç†
            for idx, row in df.iterrows():
                for url_col in url_columns:
                    url = str(row[url_col]).strip()
                    if url and url != 'nan' and ('http' in url or '.' in url):
                        try:
                            # HTMLã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—
                            html_content = self.fetch_html_body(url)

                            if "ã‚¨ãƒ©ãƒ¼" not in html_content:
                                # ã‚¿ã‚¤ãƒˆãƒ«åˆ—ãŒã‚ã‚Œã°ä½¿ç”¨ã€ãªã‘ã‚Œã°URLã‹ã‚‰ç”Ÿæˆ
                                title_cols = [col for col in df.columns if any(keyword in col.lower() for keyword in ['title', 'ã‚¿ã‚¤ãƒˆãƒ«', 'é¡Œå', 'åå‰'])]
                                if title_cols:
                                    title = str(row[title_cols[0]])
                                else:
                                    title = f"Webãƒšãƒ¼ã‚¸: {urlparse(url).netloc}"

                                # RAGã«è¿½åŠ 
                                filename = f"{title}_{idx}.html"
                                success = self.rag_manager.add_document(
                                    product_name, filename, html_content.encode('utf-8')
                                )

                                if success:
                                    results["processed_urls"] += 1
                                else:
                                    results["failed_urls"] += 1
                                    results["error_details"].append(f"RAGè¿½åŠ å¤±æ•—: {url}")
                            else:
                                results["failed_urls"] += 1
                                results["error_details"].append(f"{url}: {html_content}")

                        except Exception as e:
                            results["failed_urls"] += 1
                            results["error_details"].append(f"{url}: {str(e)}")

            return results

        except Exception as e:
            return {"success": False, "error": f"CSVå‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}"}

    def create_url_template_csv(self) -> bytes:
        """URLå–å¾—ç”¨ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆCSVã‚’ä½œæˆ"""
        template_data = {
            "ã‚¿ã‚¤ãƒˆãƒ«": [
                "ä¼šç¤¾æ¦‚è¦ãƒšãƒ¼ã‚¸",
                "è£½å“ç´¹ä»‹ãƒšãƒ¼ã‚¸",
                "æ–™é‡‘ãƒ—ãƒ©ãƒ³ãƒšãƒ¼ã‚¸",
                "ã‚µãƒãƒ¼ãƒˆãƒšãƒ¼ã‚¸",
                "ã‚ˆãã‚ã‚‹è³ªå•",
            ],
            "URL": [
                "https://example.com/about",
                "https://example.com/products",
                "https://example.com/pricing",
                "https://example.com/support",
                "https://example.com/faq",
            ],
            "èª¬æ˜": [
                "ä¼šç¤¾ã®åŸºæœ¬æƒ…å ±",
                "è£½å“ã®è©³ç´°æ©Ÿèƒ½",
                "ä¾¡æ ¼ä½“ç³»ã¨æ–™é‡‘ãƒ—ãƒ©ãƒ³",
                "ã‚µãƒãƒ¼ãƒˆä½“åˆ¶",
                "ã‚ˆãã‚ã‚‹è³ªå•ã¨å›ç­”",
            ],
        }

        df = pd.DataFrame(template_data)

        # CSVã¨ã—ã¦ãƒ¡ãƒ¢ãƒªä¸Šã«ä½œæˆ
        csv_buffer = io.StringIO()
        df.to_csv(csv_buffer, index=False, encoding="utf-8-sig")
        return csv_buffer.getvalue().encode("utf-8-sig")

    def create_template_csv(self) -> bytes:
        """Q&Aå½¢å¼ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆCSVã‚’ä½œæˆ"""
        template_data = {
            "è³ªå•": [
                "è£½å“ã®ä¾¡æ ¼ã¯ã„ãã‚‰ã§ã™ã‹ï¼Ÿ",
                "è£½å“ã®ä¸»ãªæ©Ÿèƒ½ã¯ä½•ã§ã™ã‹ï¼Ÿ",
                "å°å…¥ã«ã¯ã©ã®ãã‚‰ã„æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ã‹ï¼Ÿ",
                "ã‚µãƒãƒ¼ãƒˆä½“åˆ¶ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„",
                "ä»–ç¤¾è£½å“ã¨ã®é•ã„ã¯ä½•ã§ã™ã‹ï¼Ÿ",
            ],
            "å›ç­”": [
                "åŸºæœ¬ãƒ—ãƒ©ãƒ³ã¯æœˆé¡10,000å††ã‹ã‚‰ã€ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºãƒ—ãƒ©ãƒ³ã¯æœˆé¡50,000å††ã‹ã‚‰ã¨ãªã£ã¦ãŠã‚Šã¾ã™ã€‚è©³ç´°ãªæ–™é‡‘ä½“ç³»ã«ã¤ã„ã¦ã¯å–¶æ¥­æ‹…å½“ã¾ã§ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚",
                "ä¸»ãªæ©Ÿèƒ½ã¨ã—ã¦ã€ãƒ‡ãƒ¼ã‚¿åˆ†æã€ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã€ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ä½œæˆã€APIé€£æºãªã©ãŒã‚ã‚Šã¾ã™ã€‚ã™ã¹ã¦ã®æ©Ÿèƒ½ã¯ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ™ãƒ¼ã‚¹ã§æä¾›ã•ã‚Œã¾ã™ã€‚",
                "é€šå¸¸ã®å°å…¥æœŸé–“ã¯1-2é€±é–“ç¨‹åº¦ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ç§»è¡Œã‚„ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºãŒå¿…è¦ãªå ´åˆã¯è¿½åŠ ã§1-2é€±é–“ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚",
                "24æ™‚é–“365æ—¥ã®ã‚µãƒãƒ¼ãƒˆä½“åˆ¶ã‚’æ•´ãˆã¦ãŠã‚Šã€ãƒ¡ãƒ¼ãƒ«ã€é›»è©±ã€ãƒãƒ£ãƒƒãƒˆã§ã®ã‚µãƒãƒ¼ãƒˆã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚å°‚ä»»ã®æŠ€è¡“è€…ãŒå¯¾å¿œã„ãŸã—ã¾ã™ã€‚",
                "å½“ç¤¾ã®è£½å“ã¯é«˜åº¦ãªAIæ©Ÿèƒ½ã¨ä½¿ã„ã‚„ã™ã„UIãŒç‰¹å¾´ã§ã€å°å…¥ã‚³ã‚¹ãƒˆã‚‚ä»–ç¤¾ã¨æ¯”è¼ƒã—ã¦30%å‰Šæ¸›å¯èƒ½ã§ã™ã€‚",
            ],
            "å‚è€ƒæ–‡çŒ®": [
                "https://example.com/pricing",
                "https://example.com/features",
                "https://example.com/implementation-guide",
                "https://example.com/support",
                "https://example.com/comparison",
            ],
        }

        df = pd.DataFrame(template_data)

        # CSVã¨ã—ã¦ãƒ¡ãƒ¢ãƒªä¸Šã«ä½œæˆ
        csv_buffer = io.StringIO()
        df.to_csv(csv_buffer, index=False, encoding="utf-8-sig")
        return csv_buffer.getvalue().encode("utf-8-sig")

    def upload_files_interface(self, product_name: str):
        st.subheader(f"ğŸ“ {product_name} ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")

        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆCSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’è¿½åŠ 
        col1, col2, col3 = st.columns([2, 1, 1])

        with col1:
            st.write("**ã‚µãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼**: TXT, PDF, DOCX, PPTX, HTML, CSV")

        with col2:
            template_csv = self.create_template_csv()
            st.download_button(
                label="ğŸ“¥ Q&Aãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ",
                data=template_csv,
                file_name=f"{product_name}_qa_template.csv",
                mime="text/csv",
                help="è³ªå•ã¨å›ç­”ã®å½¢å¼ã§CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã™ã‚‹éš›ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã§ã™",
            )

        with col3:
            url_template_csv = self.create_url_template_csv()
            st.download_button(
                label="ğŸŒ URLãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ",
                data=url_template_csv,
                file_name=f"{product_name}_url_template.csv",
                mime="text/csv",
                help="Webãƒšãƒ¼ã‚¸ã®URLã‚’è¨˜è¼‰ã—ã¦HTMLã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—ã™ã‚‹éš›ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã§ã™",
            )

        st.markdown("---")

        # CSVå½¢å¼ã®èª¬æ˜ã‚’è¿½åŠ 
        with st.expander("ğŸ“‹ CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ä½¿ç”¨æ–¹æ³•", expanded=False):
            st.markdown(
                """
            **CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯3ã¤ã®å‡¦ç†æ–¹æ³•ãŒã‚ã‚Šã¾ã™:**

            ## 1. Q&Aãƒšã‚¢å½¢å¼
            è³ªç–‘å¿œç­”å½¢å¼ã§ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã—ã¾ã™ï¼š
            - **1åˆ—ç›®**: è³ªå•å†…å®¹ï¼ˆå¿…é ˆï¼‰
            - **2åˆ—ç›®**: å›ç­”å†…å®¹ï¼ˆå¿…é ˆï¼‰
            - **3åˆ—ç›®**: å‚è€ƒæ–‡çŒ®ãƒ»ãƒªãƒ³ã‚¯ï¼ˆä»»æ„ï¼‰

            **æ¨å¥¨ã‚«ãƒ©ãƒ å:**
            ```
            è³ªå•,å›ç­”,å‚è€ƒæ–‡çŒ®
            ```

            ## 2. URLä¸€æ‹¬å–å¾— ğŸŒ NEW!
            Webãƒšãƒ¼ã‚¸ã®URLã‹ã‚‰HTMLã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è‡ªå‹•å–å¾—ã—ã¾ã™ï¼š
            - **URLåˆ—**: Webãƒšãƒ¼ã‚¸ã®URLï¼ˆå¿…é ˆï¼‰
            - **ã‚¿ã‚¤ãƒˆãƒ«åˆ—**: ãƒšãƒ¼ã‚¸ã®ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆæ¨å¥¨ï¼‰
            - **èª¬æ˜åˆ—**: ãƒšãƒ¼ã‚¸ã®èª¬æ˜ï¼ˆä»»æ„ï¼‰

            **æ¨å¥¨ã‚«ãƒ©ãƒ å:**
            ```
            ã‚¿ã‚¤ãƒˆãƒ«,URL,èª¬æ˜
            ```

            **ä½¿ç”¨ä¾‹:**
            ```
            ã‚¿ã‚¤ãƒˆãƒ«,URL,èª¬æ˜
            "ä¼šç¤¾æ¦‚è¦","https://example.com/about","ä¼šç¤¾ã®åŸºæœ¬æƒ…å ±"
            "è£½å“æƒ…å ±","https://example.com/products","è£½å“ã®è©³ç´°æ©Ÿèƒ½"
            ```

            ## 3. é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼
            CSVå…¨ä½“ã‚’1ã¤ã®æ–‡æ›¸ã¨ã—ã¦å‡¦ç†ã—ã¾ã™ã€‚

            **æ³¨æ„äº‹é …:**
            - URLä¸€æ‹¬å–å¾—ã§ã¯ã€å„URLã®HTMLã®bodyã‚¿ã‚°å†…å®¹ã‚’è‡ªå‹•çš„ã«æŠ½å‡ºã—ã¾ã™
            - HTTPSã¨HTTPä¸¡æ–¹ã«å¯¾å¿œã—ã¦ã„ã¾ã™
            - ãƒšãƒ¼ã‚¸å–å¾—ã«å¤±æ•—ã—ãŸURLã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™
            - ä¸Šè¨˜ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦å‚è€ƒã«ã—ã¦ãã ã•ã„
            """
            )

        uploaded_files = st.file_uploader(
            "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
            type=list(self.supported_extensions.keys()),
            accept_multiple_files=True,
            key=f"uploader_{product_name}",
        )

        if uploaded_files:
            for uploaded_file in uploaded_files:
                if self.is_supported_file(uploaded_file.name):
                    file_type = self.get_file_type(uploaded_file.name)

                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.write(f"ğŸ“„ {uploaded_file.name} ({file_type.upper()})")

                    with col2:
                        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯ç‰¹åˆ¥ãªå‡¦ç†ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’æä¾›
                        if file_type == "csv":
                            csv_process_type = st.selectbox(
                                "CSVå‡¦ç†æ–¹æ³•:",
                                ["Q&Aãƒšã‚¢å½¢å¼", "URLä¸€æ‹¬å–å¾—", "é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼"],
                                key=f"csv_type_{uploaded_file.name}_{product_name}",
                                help="Q&Aãƒšã‚¢å½¢å¼: å„è¡Œã‚’è³ªå•-å›ç­”ãƒšã‚¢ã¨ã—ã¦å€‹åˆ¥å‡¦ç†\nURLä¸€æ‹¬å–å¾—: CSVã®URLã‹ã‚‰HTMLã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—\né€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼: CSVå…¨ä½“ã‚’1ã¤ã®æ–‡æ›¸ã¨ã—ã¦å‡¦ç†",
                            )

                        if st.button(f"è¿½åŠ ", key=f"add_{uploaded_file.name}_{product_name}"):
                            with st.spinner("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ä¸­..."):
                                # CSVãƒ•ã‚¡ã‚¤ãƒ«ã§Q&Aãƒšã‚¢å½¢å¼ãŒé¸æŠã•ã‚ŒãŸå ´åˆ
                                if file_type == "csv" and csv_process_type == "Q&Aãƒšã‚¢å½¢å¼":
                                    success = self.rag_manager.add_csv_as_qa_pairs(
                                        product_name, uploaded_file.name, uploaded_file.read()
                                    )
                                # CSVãƒ•ã‚¡ã‚¤ãƒ«ã§URLä¸€æ‹¬å–å¾—ãŒé¸æŠã•ã‚ŒãŸå ´åˆ
                                elif file_type == "csv" and csv_process_type == "URLä¸€æ‹¬å–å¾—":
                                    csv_content = uploaded_file.read()
                                    result = self.process_url_csv(product_name, csv_content)

                                    if result["success"]:
                                        st.success(f"âœ… URLå‡¦ç†å®Œäº†: {result['processed_urls']}ä»¶ã®URLã‹ã‚‰HTMLã‚’å–å¾—ã—ã¾ã—ãŸ")
                                        if result["failed_urls"] > 0:
                                            st.warning(f"âš ï¸ {result['failed_urls']}ä»¶ã®URLã§å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
                                            if result["error_details"]:
                                                with st.expander("ã‚¨ãƒ©ãƒ¼è©³ç´°", expanded=False):
                                                    for error in result["error_details"][:5]:  # æœ€å¤§5ä»¶ã¾ã§è¡¨ç¤º
                                                        st.write(f"â€¢ {error}")
                                        # ãƒ•ã‚¡ã‚¤ãƒ«è¿½åŠ æ™‚ã®è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
                                        feedback_manager._trigger_auto_backup("URL content addition backup")
                                        success = True
                                    else:
                                        st.error(f"âŒ URLå‡¦ç†ã‚¨ãƒ©ãƒ¼: {result['error']}")
                                        success = False
                                else:
                                    success = self.rag_manager.add_document(
                                        product_name, uploaded_file.name, uploaded_file.read(), file_type
                                    )

                                if success and csv_process_type != "URLä¸€æ‹¬å–å¾—":
                                    st.success(f"âœ… {uploaded_file.name} ãŒè¿½åŠ ã•ã‚Œã¾ã—ãŸ")
                                    # ãƒ•ã‚¡ã‚¤ãƒ«è¿½åŠ æ™‚ã®è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
                                    feedback_manager._trigger_auto_backup("File addition backup")
                                elif not success and csv_process_type != "URLä¸€æ‹¬å–å¾—":
                                    st.error(f"âŒ {uploaded_file.name} ã®è¿½åŠ ã«å¤±æ•—ã—ã¾ã—ãŸ")
                else:
                    st.warning(f"âš ï¸ {uploaded_file.name} ã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™")

    def manage_existing_files(self, product_name: str):
        st.subheader(f"ğŸ“‹ {product_name} ã®ç™»éŒ²æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«")

        documents = self.rag_manager.list_documents(product_name)

        if not documents:
            st.info("ç™»éŒ²ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚ã‚Šã¾ã›ã‚“")
            return

        for doc_name in documents:
            col1, col2 = st.columns([3, 1])
            with col1:
                st.write(f"ğŸ“„ {doc_name}")

            with col2:
                if st.button(f"å‰Šé™¤", key=f"delete_{doc_name}_{product_name}"):
                    if st.session_state.get(f"confirm_delete_{doc_name}_{product_name}", False):
                        with st.spinner("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ä¸­..."):
                            success = self.rag_manager.remove_document(product_name, doc_name)

                            if success:
                                st.success(f"âœ… {doc_name} ãŒå‰Šé™¤ã•ã‚Œã¾ã—ãŸ")
                                st.rerun()
                            else:
                                st.error(f"âŒ {doc_name} ã®å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ")

                        st.session_state[f"confirm_delete_{doc_name}_{product_name}"] = False
                    else:
                        st.session_state[f"confirm_delete_{doc_name}_{product_name}"] = True
                        st.warning("âš ï¸ ã‚‚ã†ä¸€åº¦ã€Œå‰Šé™¤ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ç¢ºèªã—ã¦ãã ã•ã„")

    def product_management_interface(self):
        st.title("ğŸ› ï¸ RAG ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†")

        # å•†æé¸æŠã¾ãŸã¯æ–°è¦ä½œæˆ
        col1, col2 = st.columns([2, 1])

        with col1:
            existing_products = self.rag_manager.list_products()
            if existing_products:
                selected_product = st.selectbox("æ—¢å­˜ã®å•†æã‚’é¸æŠ", ["æ–°è¦ä½œæˆ"] + existing_products)
            else:
                selected_product = "æ–°è¦ä½œæˆ"

        with col2:
            if selected_product == "æ–°è¦ä½œæˆ":
                new_product = st.text_input("æ–°ã—ã„å•†æåã‚’å…¥åŠ›")
                if new_product:
                    selected_product = new_product

        if selected_product and selected_product != "æ–°è¦ä½œæˆ":
            st.divider()

            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            self.upload_files_interface(selected_product)

            st.divider()

            # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†
            self.manage_existing_files(selected_product)

        elif selected_product == "æ–°è¦ä½œæˆ":
            st.info("ğŸ‘† æ–°ã—ã„å•†æåã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

    def get_supported_formats_info(self):
        return {
            "txt": "ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«",
            "pdf": "PDFãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ",
            "docx": "Wordæ–‡æ›¸",
            "html": "HTMLãƒ•ã‚¡ã‚¤ãƒ«",
            "csv": "CSVãƒ•ã‚¡ã‚¤ãƒ«",
        }


    def save_uploaded_file(self, uploaded_file, product_name: str):
        """ğŸ›¡ï¸ æ°¸ç¶šåŒ–å¯¾å¿œã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜"""
        # æ°¸ç¶šåŒ–ã‚·ã‚¹ãƒ†ãƒ ã‚’èª­ã¿è¾¼ã¿
        from config.persistent_storage import persistent_storage
    
        # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ°¸ç¶šåŒ–ä¿å­˜
        saved_path = persistent_storage.save_uploaded_file(uploaded_file, product_name)
    
        if saved_path:
            # ã‚¹ãƒ†ãƒƒãƒ—2: RAGã‚·ã‚¹ãƒ†ãƒ ã«ç™»éŒ²ï¼ˆæ¤œç´¢ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ï¼‰
            success = self.rag_manager.add_document(
                file_path=saved_path,
                product_name=product_name
            )
    
            if success:
                st.success(f"âœ… {uploaded_file.name} ã‚’æ°¸ç¶šåŒ–ã—ã¾ã—ãŸï¼")
                st.info(f"ğŸ“ ä¿å­˜å ´æ‰€: {saved_path}")
                return True
    
        st.error("âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã®æ°¸ç¶šåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return False
