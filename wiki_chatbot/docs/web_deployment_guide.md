# ğŸŒ Wiki Chatbot Web ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå®Œå…¨ã‚¬ã‚¤ãƒ‰

**ğŸ¯ å¯¾è±¡èª­è€…**: ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å®Œå…¨åˆå¿ƒè€…ã€œä¸Šç´šè€…ã¾ã§èª°ã§ã‚‚å¯¾å¿œ
**â±ï¸ æ‰€è¦æ™‚é–“**: 15åˆ†ï¼ˆæœ€é€Ÿãƒ‡ãƒ—ãƒ­ã‚¤ï¼‰ã€œ60åˆ†ï¼ˆæœ¬æ ¼é‹ç”¨è¨­å®šï¼‰
**ğŸ’» å‰ææ¡ä»¶**: ãƒ‘ã‚½ã‚³ãƒ³ã¨ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šã®ã¿ï¼ˆç‰¹åˆ¥ãªã‚½ãƒ•ãƒˆä¸è¦ï¼‰
**ğŸ’° è²»ç”¨**: å®Œå…¨ç„¡æ–™ã€œæœˆæ•°ç™¾å††ï¼ˆä½¿ç”¨é‡ã«ã‚ˆã‚‹ï¼‰

> ğŸš€ **ã“ã®ã‚¬ã‚¤ãƒ‰ã®è¶…å¼·åŠ›ãªç‰¹å¾´**
> - **ğŸ”° å®Œå…¨åˆå¿ƒè€…ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼**: ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°çµŒé¨“ã‚¼ãƒ­ã§ã‚‚OKï¼ç”»é¢ã®é€šã‚Šã«é€²ã‚ã‚‹ã ã‘
> - **ğŸ“‹ ã‚³ãƒ”ãƒšã§å®Œçµ**: ã‚³ãƒ¼ãƒ‰ã¯å…¨ã¦ç”¨æ„æ¸ˆã¿ã€‚ã‚³ãƒ”ãƒ¼ï¼†ãƒšãƒ¼ã‚¹ãƒˆã ã‘ã§å‹•ãã¾ã™
> - **ğŸ›¡ï¸ ãƒ‡ãƒ¼ã‚¿å®Œå…¨ä¿è­·**: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»ãƒãƒ£ãƒƒãƒˆå±¥æ­´ãŒçµ¶å¯¾ã«æ¶ˆãˆãªã„æ°¸ç¶šåŒ–ã‚·ã‚¹ãƒ†ãƒ 
> - **ğŸ†“ å®Œå…¨ç„¡æ–™ã‚¹ã‚¿ãƒ¼ãƒˆ**: æœ€åˆã¯1å††ã‚‚ã‹ã‹ã‚‰ãšã«å§‹ã‚ã‚‰ã‚Œã¾ã™
> - **ğŸ“± ã‚¹ãƒãƒ›å¯¾å¿œ**: ãƒ‘ã‚½ã‚³ãƒ³ã§ã‚‚ã‚¹ãƒãƒ›ã§ã‚‚ä½¿ãˆã‚‹å®Œå…¨ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–
> - **ğŸ”’ ä¼æ¥­ãƒ¬ãƒ™ãƒ«ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£**: ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰èªè¨¼ãƒ»ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ãƒ»ä¸æ­£ã‚¢ã‚¯ã‚»ã‚¹é˜²æ­¢
> - **ğŸ”§ ã´ã‚ˆã´ã‚ˆåˆå¿ƒè€…ã‚µãƒãƒ¼ãƒˆ**: ã€Œã“ã‚Œä½•ï¼Ÿã€ã‚’å…¨ã¦è§£èª¬ã€‚å°‚é–€ç”¨èªã¯ä½¿ã„ã¾ã›ã‚“ï¼

## ğŸ‰ ã“ã®ã‚¬ã‚¤ãƒ‰ã§ä½œã‚Œã‚‹ã‚‚ã®

âœ… **ä¸–ç•Œä¸­ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½**ãªè‡ªåˆ†å°‚ç”¨ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ
âœ… **PDFãƒ»Wordãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹**ã«ã¤ã„ã¦è³ªå•ã§ãã‚‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ
âœ… **ãƒ‡ãƒ¼ã‚¿æ°¸ç¶šåŒ–**ã§ãƒ•ã‚¡ã‚¤ãƒ«ãŒçµ¶å¯¾ã«æ¶ˆãˆãªã„å®‰å¿ƒã‚·ã‚¹ãƒ†ãƒ 
âœ… **ç®¡ç†ç”»é¢ä»˜ã**ã§åˆ©ç”¨çŠ¶æ³ã‚‚ä¸å¯§ã«åˆ†æ
âœ… **ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ä¿è­·**ã§ä¸æ­£åˆ©ç”¨ã‚’å®Œå…¨ãƒ–ãƒ­ãƒƒã‚¯

## ğŸŒˆ æŠ€è¡“çŸ¥è­˜ã‚¼ãƒ­ã§ã‚‚å¤§ä¸ˆå¤«ï¼

> ğŸ¤— **ã€Œãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ãªã‚“ã¦å…¨ç„¶ã‚ã‹ã‚‰ãªã„...ã€ã¨ã„ã†æ–¹ã¸**
> ã“ã®ã‚¬ã‚¤ãƒ‰ã¯ã€Œã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ¼ã£ã¦ã©ã†ã‚„ã£ã¦å‹•ãã®ï¼Ÿã€ãƒ¬ãƒ™ãƒ«ã®æ–¹ã§ã‚‚ç†è§£ã§ãã‚‹ã‚ˆã†æ›¸ã‹ã‚Œã¦ã„ã¾ã™ã€‚
> é›£ã—ã„å°‚é–€ç”¨èªã¯ä¸€åˆ‡ä½¿ã‚ãšã€å…¨ã¦ã‚’æ—¥å¸¸èªã§èª¬æ˜ã—ã¾ã™ã€‚
> ã‚³ãƒ”ãƒšã™ã‚‹ã ã‘ã§å‹•ãã®ã§ã€ã‚³ãƒ¼ãƒ‰ã‚’ç†è§£ã™ã‚‹å¿…è¦ã‚‚ã‚ã‚Šã¾ã›ã‚“ï¼

---

## ğŸ“‹ ç›®æ¬¡

### ğŸ”° **STEP 1: è¶…åˆå¿ƒè€…å‘ã‘ï¼ˆã¾ãšã¯ã“ã“ã‹ã‚‰ï¼ï¼‰**
1. [ğŸ¬ 5åˆ†ã§ç†è§£ï¼å…¨ä½“ã®æµã‚Œ](#1-5åˆ†ã§ç†è§£å…¨ä½“ã®æµã‚Œ)
2. [ğŸ”‘ AIã¨ãŠè©±ã™ã‚‹ãŸã‚ã®ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰å–å¾—](#2-aiã¨ãŠè©±ã™ã‚‹ãŸã‚ã®ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰å–å¾—)
3. [ğŸ“ è‡ªåˆ†ã®ãƒ•ã‚¡ã‚¤ãƒ«ç½®ãå ´ã‚’ä½œã‚ã†](#3-è‡ªåˆ†ã®ãƒ•ã‚¡ã‚¤ãƒ«ç½®ãå ´ã‚’ä½œã‚ã†)
4. [ğŸŒ ä¸–ç•Œã«å…¬é–‹ï¼ã‚ãªãŸã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ](#4-ä¸–ç•Œã«å…¬é–‹ã‚ãªãŸã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ)

### ğŸ’¾ **STEP 2: ãƒ‡ãƒ¼ã‚¿ã‚’çµ¶å¯¾ã«æ¶ˆã•ãªã„è¨­å®šï¼ˆè¶…é‡è¦ï¼ï¼‰**
5. [ğŸ›¡ï¸ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ°¸é ã«ä¿è­·](#5-ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ°¸é ã«ä¿è­·)
6. [ğŸ’¬ ä¼šè©±å±¥æ­´ã‚’æ°¸ä¹…ä¿å­˜](#6-ä¼šè©±å±¥æ­´ã‚’æ°¸ä¹…ä¿å­˜)
7. [ğŸ” æ‚ªã„äººã‹ã‚‰å®ˆã‚‹ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£](#7-æ‚ªã„äººã‹ã‚‰å®ˆã‚‹ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£)

### ğŸ¢ **STEP 3: ä¼šç¤¾ã§ã‚‚ä½¿ãˆã‚‹æœ¬æ ¼è¨­å®šï¼ˆä¸­ç´šè€…å‘ã‘ï¼‰**
8. [â˜ï¸ å¤§ããªä¼šç¤¾å‘ã‘ã‚¯ãƒ©ã‚¦ãƒ‰è¨­å®š](#8-å¤§ããªä¼šç¤¾å‘ã‘ã‚¯ãƒ©ã‚¦ãƒ‰è¨­å®š)
9. [âš¡ ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ï¼†ç¯€ç´„è¡“](#9-ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ç¯€ç´„è¡“)
10. [ğŸ†˜ å›°ã£ãŸæ™‚ã®è§£æ±ºæ–¹æ³•](#10-å›°ã£ãŸæ™‚ã®è§£æ±ºæ–¹æ³•)

### ğŸ“š **STEP 4: ã‚‚ã£ã¨è©³ã—ãçŸ¥ã‚ŠãŸã„äººå‘ã‘**
11. [ğŸ¤“ æŠ€è¡“çš„ãªè©³ç´°èª¬æ˜](#11-æŠ€è¡“çš„ãªè©³ç´°èª¬æ˜)
12. [ğŸ”§ ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºæ–¹æ³•](#12-ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºæ–¹æ³•)
13. [ğŸ“ˆ é‹ç”¨ãƒ»ä¿å®ˆã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹](#13-é‹ç”¨ä¿å®ˆã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹)

---

## 1. ğŸ¬ 5åˆ†ã§ç†è§£ï¼å…¨ä½“ã®æµã‚Œ

### ğŸŒŸ ã€Œã“ã‚Œã‹ã‚‰ä½•ã‚’ã™ã‚‹ã®ï¼Ÿã€ã‚’å„ªã—ãèª¬æ˜

åˆå¿ƒè€…ã®æ–¹ã§ã‚‚è¿·ã‚ãªã„ã‚ˆã†ã€ã¾ãšã¯ **ã€Œä»Šã‹ã‚‰ä½•ã‚’ã™ã‚‹ã®ã‹ã€** ã‚’åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¾ã™ï¼

#### ğŸ  å®¶ã‚’å»ºã¦ã‚‹ã®ã¨åŒã˜ï¼ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆä½œæˆã®æµã‚Œ

```
ğŸ—ï¸ ã‚ãªãŸã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚’ä½œã‚‹æ‰‹é †ï¼ˆå®¶ã‚’å»ºã¦ã‚‹ã®ã¨åŒã˜ï¼ï¼‰

1. ğŸ”‘ ææ–™ã®æº–å‚™     â†’ AIã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½¿ã†ãŸã‚ã®ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’ã‚‚ã‚‰ã†
   ï¼ˆå»ºæã‚’è²·ã†ï¼‰      ï¼ˆOpenAIã¨ã„ã†ä¼šç¤¾ã‹ã‚‰ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’ã‚‚ã‚‰ã„ã¾ã™ï¼‰

2. ğŸ“ åœŸåœ°ã®æº–å‚™     â†’ ã‚ãªãŸã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’ç½®ãå ´æ‰€ã‚’å€Ÿã‚Šã‚‹
   ï¼ˆåœŸåœ°ã‚’å€Ÿã‚Šã‚‹ï¼‰    ï¼ˆGitHubã¨ã„ã†ç„¡æ–™ã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½¿ã„ã¾ã™ï¼‰

3. ğŸ  å®¶ã®å»ºè¨­      â†’ ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆã§èª°ã§ã‚‚ä½¿ãˆã‚‹ã‚ˆã†ã«ã™ã‚‹
   ï¼ˆå®¶ã‚’å»ºã¦ã‚‹ï¼‰      ï¼ˆStreamlit Cloudã¨ã„ã†ç„¡æ–™ã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½¿ã„ã¾ã™ï¼‰

4. ğŸ›¡ï¸ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£   â†’ æ‚ªã„äººãŒå‹æ‰‹ã«ä½¿ãˆãªã„ã‚ˆã†ã«éµã‚’ã‹ã‘ã‚‹
   ï¼ˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ï¼‰    ï¼ˆãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã§ä¿è­·ã—ã¾ã™ï¼‰

5. ğŸ’¾ å¼•ã£è¶Šã—æº–å‚™   â†’ ãƒ‡ãƒ¼ã‚¿ãŒæ¶ˆãˆãªã„ã‚ˆã†ã«æ°¸ä¹…ä¿å­˜è¨­å®š
   ï¼ˆå®¶å…·ã‚’é‹ã¶ï¼‰     ï¼ˆå¤§åˆ‡ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµ¶å¯¾ã«æ¶ˆãˆãªã„ã‚ˆã†ã«ã—ã¾ã™ï¼‰
```

### ğŸ¯ **å®Œæˆã™ã‚‹ã¨ä½•ãŒã§ãã‚‹ï¼Ÿ**

âœ… **ğŸ“± ã‚¹ãƒãƒ›ã‹ã‚‰ã§ã‚‚ä½¿ãˆã‚‹**: iPhoneã€Androidã€ãƒ‘ã‚½ã‚³ãƒ³ã©ã‚Œã§ã‚‚OKï¼
âœ… **ğŸŒ ä¸–ç•Œä¸­ã©ã“ã‹ã‚‰ã§ã‚‚**: ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆãŒã‚ã‚Œã°åœ°çƒã®è£å´ã‹ã‚‰ã§ã‚‚ã‚¢ã‚¯ã‚»ã‚¹
âœ… **ğŸ“„ PDFè³ªå•ãƒã‚·ãƒ³**: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸPDFãƒ»Wordãƒ•ã‚¡ã‚¤ãƒ«ã«ã¤ã„ã¦ä½•ã§ã‚‚è³ªå•
âœ… **ğŸ§  AIãŒå›ç­”**: ChatGPTã¨åŒã˜æŠ€è¡“ã§çš„ç¢ºã«ç­”ãˆã¦ãã‚Œã¾ã™
âœ… **ğŸ” å®‰å…¨ãƒ»å®‰å¿ƒ**: ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ä¿è­·ã§é–¢ä¿‚è€…ä»¥å¤–ã¯ä½¿ç”¨ä¸å¯
âœ… **ğŸ’¾ ãƒ‡ãƒ¼ã‚¿æ°¸ä¹…ä¿å­˜**: ä¸€åº¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã¯çµ¶å¯¾ã«æ¶ˆãˆã¾ã›ã‚“

### â° **å®Ÿéš›ã«ã‹ã‹ã‚‹æ™‚é–“**

| æ‰‹é † | èª¬æ˜ | æ‰€è¦æ™‚é–“ | é›£æ˜“åº¦ |
|------|------|----------|--------|
| ğŸ”‘ ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰å–å¾— | OpenAIã®ã‚µã‚¤ãƒˆã§ã‚¢ã‚«ã‚¦ãƒ³ãƒˆä½œæˆ | **3åˆ†** | â­â˜†â˜†ï¼ˆè¶…ç°¡å˜ï¼‰ |
| ğŸ“ ç½®ãå ´æ‰€æº–å‚™ | GitHubã§ãƒ•ã‚¡ã‚¤ãƒ«ç½®ãå ´ã‚’ä½œæˆ | **5åˆ†** | â­â˜†â˜†ï¼ˆè¶…ç°¡å˜ï¼‰ |
| ğŸŒ Webå…¬é–‹ | Streamlit Cloudã§ã‚µã‚¤ãƒˆå…¬é–‹ | **7åˆ†** | â­â­â˜†ï¼ˆç°¡å˜ï¼‰ |
| ğŸ›¡ï¸ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®š | ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒ»æš—å·åŒ–è¨­å®š | **5åˆ†** | â­â­â˜†ï¼ˆç°¡å˜ï¼‰ |
| ğŸ’¾ æ°¸ç¶šåŒ–è¨­å®š | ãƒ‡ãƒ¼ã‚¿æ¶ˆå¤±é˜²æ­¢è¨­å®š | **10åˆ†** | â­â­â­ï¼ˆå°‘ã—æ³¨æ„ï¼‰ |

**åˆè¨ˆ: ç´„30åˆ†** ï¼ˆã‚³ãƒ¼ãƒ’ãƒ¼ã‚’1æ¯é£²ã‚€æ™‚é–“ã§å®Œæˆï¼ï¼‰

### ğŸ’° **æ–™é‡‘ã¯ã„ãã‚‰ï¼Ÿ**

> ğŸ†“ **æœ€åˆã¯å®Œå…¨ç„¡æ–™ã§ã‚¹ã‚¿ãƒ¼ãƒˆå¯èƒ½ï¼**

| ã‚µãƒ¼ãƒ“ã‚¹ | æ–™é‡‘ | ä½•ã‚’ã—ã¦ãã‚Œã‚‹ï¼Ÿ |
|----------|------|----------------|
| **GitHub** | **å®Œå…¨ç„¡æ–™** | ã‚ãªãŸã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’ä¿ç®¡ |
| **Streamlit Cloud** | **å®Œå…¨ç„¡æ–™** | Webã‚µã‚¤ãƒˆã¨ã—ã¦å…¬é–‹ |
| **OpenAI API** | **æœˆ$3ã€œ10ç¨‹åº¦** | AIãŒå›ç­”ã‚’ä½œæˆ |

**æœˆé¡300å††ã€œ1,000å††ç¨‹åº¦** ã§æœ¬æ ¼çš„ãªAIãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆãŒé‹ç”¨ã§ãã¾ã™ï¼
ï¼ˆç¼¶ã‚³ãƒ¼ãƒ’ãƒ¼3æœ¬åˆ†ã®å€¤æ®µã§ã™ï¼‰

### ğŸš¨ **çµ¶å¯¾ã«èª­ã‚“ã§ï¼è¶…é‡è¦ãªæ³¨æ„ç‚¹**

> âš ï¸ **ã€Œãƒ‡ãƒ¼ã‚¿æ°¸ç¶šåŒ–ã€ã¯å¿…ãšè¨­å®šã—ã¦ãã ã•ã„ï¼**
>
> ã“ã‚Œã‚’è¨­å®šã—ãªã„ã¨ã€ä»¥ä¸‹ã®ã‚ˆã†ãª **æ‚²æƒ¨ãªã“ã¨** ãŒèµ·ã“ã‚Šã¾ã™ï¼š
> - ğŸ“„ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸPDFãƒ•ã‚¡ã‚¤ãƒ«ãŒ **å…¨éƒ¨æ¶ˆãˆã‚‹**
> - ğŸ’¬ ä»Šã¾ã§ã®ãƒãƒ£ãƒƒãƒˆå±¥æ­´ãŒ **å…¨éƒ¨æ¶ˆãˆã‚‹**
> - ğŸ”„ ã‚¢ãƒ—ãƒªãŒå†èµ·å‹•ã™ã‚‹ãŸã³ã« **æœ€åˆã‹ã‚‰ã‚„ã‚Šç›´ã—**
> - ğŸ˜­ ã›ã£ã‹ãã®è‹¦åŠ´ãŒ **æ°´ã®æ³¡**
>
> ã§ã‚‚å¤§ä¸ˆå¤«ï¼ã“ã®ã‚¬ã‚¤ãƒ‰ã®é€šã‚Šã«é€²ã‚ã‚Œã°ã€**çµ¶å¯¾ã«æ¶ˆãˆãªã„è¨­å®š** ã«ãªã‚Šã¾ã™ï¼

---

### ğŸª **ã„ã‚ˆã„ã‚ˆå§‹ã‚ã¾ã—ã‚‡ã†ï¼**

æº–å‚™ã¯ã§ãã¾ã—ãŸã‹ï¼Ÿãã‚Œã§ã¯ã€ä¸€ç·’ã« **ã‚ãªãŸå°‚ç”¨ã®AIãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ** ã‚’ä½œã£ã¦ã„ãã¾ã—ã‚‡ã†ï¼

åˆå¿ƒè€…ã®æ–¹ã‚‚ã€ã€Œ1ã¤ãšã¤ã‚†ã£ãã‚Šã€é€²ã‚ã‚Œã°å¤§ä¸ˆå¤«ã§ã™ã€‚
åˆ†ã‹ã‚‰ãªã„ã“ã¨ãŒã‚ã£ã¦ã‚‚ã€ã“ã®ã‚¬ã‚¤ãƒ‰ã« **å…¨ã¦ç­”ãˆ** ãŒæ›¸ã„ã¦ã‚ã‚Šã¾ã™ï¼

ğŸš€ **æ¬¡ã®STEP**: [ğŸ”‘ AIã¨ãŠè©±ã™ã‚‹ãŸã‚ã®ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰å–å¾—](#2-aiã¨ãŠè©±ã™ã‚‹ãŸã‚ã®ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰å–å¾—)

---

## 2. ğŸ”‘ AIã¨ãŠè©±ã™ã‚‹ãŸã‚ã®ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰å–å¾—

### ğŸ¤” **ã€ŒAPIã‚­ãƒ¼ã€ã£ã¦ä½•ï¼Ÿ**

> ğŸ’¡ **è¶…ç°¡å˜ã«èª¬æ˜ï¼**
>
> APIã‚­ãƒ¼ = **AIã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½¿ã†ãŸã‚ã®ä¼šå“¡è¨¼** ã ã¨æ€ã£ã¦ãã ã•ã„ï¼
>
> - ğŸ“± ã‚¹ãƒãƒ›ã‚¢ãƒ—ãƒªã‚’ä½¿ã†ã®ã«ã€Œã‚¢ã‚«ã‚¦ãƒ³ãƒˆã€ãŒå¿…è¦ãªã®ã¨åŒã˜
> - ğŸª ãŠåº—ã§è²·ã„ç‰©ã™ã‚‹ã®ã«ã€Œä¼šå“¡ã‚«ãƒ¼ãƒ‰ã€ãŒå¿…è¦ãªã®ã¨åŒã˜
> - ğŸš— è»Šã‚’é‹è»¢ã™ã‚‹ã®ã«ã€Œé‹è»¢å…è¨±è¨¼ã€ãŒå¿…è¦ãªã®ã¨åŒã˜
>
> ã¤ã¾ã‚Šã€**ã€Œç§ã¯ã¡ã‚ƒã‚“ã¨ã—ãŸåˆ©ç”¨è€…ã§ã™ã‚ˆã€** ã¨ã„ã†ã“ã¨ã‚’AIã«è¨¼æ˜ã™ã‚‹ãŸã‚ã® **èº«åˆ†è¨¼æ˜æ›¸** ã§ã™ï¼

### ğŸ† **OpenAIï¼ˆChatGPTã®ä¼šç¤¾ï¼‰ãŒãªãœæœ€é«˜ï¼Ÿ**

OpenAIã‚’é¸ã¶ã¹ãç†ç”±ã‚’ã€åˆå¿ƒè€…å‘ã‘ã«åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¾ã™ï¼š

| ğŸŒŸ ç†ç”± | ğŸ”° åˆå¿ƒè€…ã«ã¨ã£ã¦ã®ãƒ¡ãƒªãƒƒãƒˆ |
|---------|---------------------------|
| **ğŸ—£ï¸ æ—¥æœ¬èªãŒè¶…å¾—æ„** | è³ªå•ã‚‚å›ç­”ã‚‚è‡ªç„¶ãªæ—¥æœ¬èªã§ã‚¹ãƒ ãƒ¼ã‚º |
| **ğŸ§  ã¨ã¦ã‚‚è³¢ã„** | çš„ç¢ºã§è©³ã—ã„å›ç­”ã‚’ã—ã¦ãã‚Œã‚‹ |
| **ğŸ“š æƒ…å ±ãŒè±Šå¯Œ** | å›°ã£ãŸæ™‚ã®è§£æ±ºæ–¹æ³•ãŒãƒãƒƒãƒˆã«ãŸãã•ã‚“ |
| **ğŸ’° æ–™é‡‘ãŒåˆ†ã‹ã‚Šã‚„ã™ã„** | ä½¿ã£ãŸåˆ†ã ã‘ã®æ˜ç¢ºãªèª²é‡‘ã‚·ã‚¹ãƒ†ãƒ  |
| **ğŸ›¡ï¸ å®‰å…¨ãƒ»å®‰å¿ƒ** | ä¸–ç•Œä¸­ã§ä½¿ã‚ã‚Œã¦ã„ã‚‹ä¿¡é ¼ã§ãã‚‹ã‚µãƒ¼ãƒ“ã‚¹ |

### ğŸ“ **å–å¾—æ‰‹é †ï¼ˆç”»é¢ã®å†™çœŸä»˜ãã§è©³ã—ãè§£èª¬ï¼ï¼‰**

#### **STEP 1: OpenAIå…¬å¼ã‚µã‚¤ãƒˆã«ã‚¢ã‚¯ã‚»ã‚¹ï¼ˆ30ç§’ï¼‰**

1. **ä»¥ä¸‹ã®ãƒªãƒ³ã‚¯ã‚’ã‚¯ãƒªãƒƒã‚¯**ã—ã¦OpenAIå…¬å¼ã‚µã‚¤ãƒˆã‚’é–‹ã„ã¦ãã ã•ã„ï¼š
   ```
   ğŸ‘† ã‚¯ãƒªãƒƒã‚¯ â†’ https://platform.openai.com/api-keys
   ```

2. **ç”»é¢ã«è¡¨ç¤ºã•ã‚Œã‚‹å†…å®¹**ï¼š
   - è‹±èªã®ã‚µã‚¤ãƒˆã§ã™ãŒã€å¿ƒé…ã—ãªã„ã§ãã ã•ã„ï¼
   - ã€ŒSign upã€ï¼ˆã‚¢ã‚«ã‚¦ãƒ³ãƒˆä½œæˆï¼‰ãƒœã‚¿ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã™

#### **STEP 2: ã‚¢ã‚«ã‚¦ãƒ³ãƒˆä½œæˆï¼ˆ2åˆ†ï¼‰**

3. **ã€ŒSign upã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯**
   - æ–°è¦ã‚¢ã‚«ã‚¦ãƒ³ãƒˆä½œæˆç”»é¢ã«ç§»å‹•ã—ã¾ã™

4. **å¿…è¦ãªæƒ…å ±ã‚’å…¥åŠ›**ï¼š
   ```
   ğŸ“§ Email addressï¼ˆãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ï¼‰
   â”—â” æ™®æ®µä½¿ã£ã¦ã„ã‚‹ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’å…¥åŠ›

   ğŸ”’ Passwordï¼ˆãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ï¼‰
   â”—â” 8æ–‡å­—ä»¥ä¸Šã®å®‰å…¨ãªãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›
       ï¼ˆä¾‹ï¼šmypassword123ï¼‰

   ğŸ‘¤ First name & Last nameï¼ˆåå‰ï¼‰
   â”—â” æœ¬åã§ãªãã¦ã‚‚OKï¼ˆä¾‹ï¼šTaro Yamadaï¼‰
   ```

5. **ãƒ¡ãƒ¼ãƒ«èªè¨¼ã‚’å®Œäº†**ï¼š
   - å…¥åŠ›ã—ãŸãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã«ç¢ºèªãƒ¡ãƒ¼ãƒ«ãŒå±Šãã¾ã™
   - ãƒ¡ãƒ¼ãƒ«å†…ã®ã€ŒVerify email addressã€ã‚’ã‚¯ãƒªãƒƒã‚¯
   - ã“ã‚Œã§ã‚¢ã‚«ã‚¦ãƒ³ãƒˆä½œæˆå®Œäº†ï¼

#### **STEP 3: APIã‚­ãƒ¼ä½œæˆï¼ˆ2åˆ†ï¼‰**

6. **APIã‚­ãƒ¼ä½œæˆç”»é¢ã«ç§»å‹•**ï¼š
   - ãƒ­ã‚°ã‚¤ãƒ³å¾Œã€å·¦å´ã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰ **ã€ŒAPI keysã€** ã‚’ã‚¯ãƒªãƒƒã‚¯

7. **æ–°ã—ã„ã‚­ãƒ¼ã‚’ä½œæˆ**ï¼š
   - **ã€ŒCreate new secret keyã€** ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
   - åå‰ã‚’èã‹ã‚ŒãŸã‚‰ **ã€ŒWikiChatbotã€** ã¨å…¥åŠ›
   - **ã€ŒCreate secret keyã€** ã‚’ã‚¯ãƒªãƒƒã‚¯

8. **ğŸš¨ è¶…é‡è¦ï¼ã‚­ãƒ¼ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ä¿å­˜**ï¼š
   ```
   âš ï¸ ç”»é¢ã«ã€Œsk-ã€ã§å§‹ã¾ã‚‹é•·ã„æ–‡å­—åˆ—ãŒè¡¨ç¤ºã•ã‚Œã¾ã™

   ä¾‹ï¼šsk-abcd1234efgh5678ijkl9012mnop3456qrst7890uvwx

   ã“ã®æ–‡å­—åˆ—ã‚’å¿…ãšã‚³ãƒ”ãƒ¼ã—ã¦ã€ãƒ¡ãƒ¢å¸³ãªã©ã«ä¿å­˜ã—ã¦ãã ã•ã„ï¼

   âš ï¸ ã“ã®ç”»é¢ã‚’é–‰ã˜ã‚‹ã¨äºŒåº¦ã¨è¡¨ç¤ºã•ã‚Œã¾ã›ã‚“ï¼
   ```

#### **STEP 4: æ–™é‡‘è¨­å®šï¼ˆ1åˆ†ï¼‰**

9. **å®‰å…¨ã®ãŸã‚æ–™é‡‘ä¸Šé™ã‚’è¨­å®š**ï¼š
   - å·¦ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã® **ã€ŒSettingsã€** â†’ **ã€ŒBillingã€** ã‚’ã‚¯ãƒªãƒƒã‚¯
   - **ã€ŒUsage limitsã€** ã‚’ã‚¯ãƒªãƒƒã‚¯
   - **ã€ŒMonthly budgetã€** ã« **ã€Œ20ã€** ã¨å…¥åŠ›ï¼ˆæœˆ20ãƒ‰ãƒ« = ç´„3,000å††ã®ä¸Šé™è¨­å®šï¼‰
   - ã“ã‚Œã§ä½¿ã„ã™ãã¦é«˜é¡è«‹æ±‚ã•ã‚Œã‚‹å¿ƒé…ãŒã‚ã‚Šã¾ã›ã‚“ï¼

### ğŸ’° **æ–™é‡‘ã«ã¤ã„ã¦ï¼ˆåˆå¿ƒè€…å‘ã‘è©³ç´°èª¬æ˜ï¼‰**

#### **ğŸ” å®Ÿéš›ã„ãã‚‰ã‹ã‹ã‚‹ã®ï¼Ÿ**

```
ğŸ“Š ãƒªã‚¢ãƒ«ãªä½¿ç”¨ä¾‹ã¨æ–™é‡‘

ğŸ  å€‹äººåˆ©ç”¨ï¼ˆå°‘ãªã‚ï¼‰
â”œâ”€ 1æ—¥10å›è³ªå• Ã— 30æ—¥ = æœˆ300å›
â”œâ”€ ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«ï¼šGPT-3.5-turboï¼ˆå®‰ã„æ–¹ï¼‰
â””â”€ æœˆé¡æ–™é‡‘ï¼šç´„$3-5ï¼ˆ450å††-750å††ï¼‰â˜•ï¸ã‚³ãƒ¼ãƒ’ãƒ¼2æ¯åˆ†

ğŸ¢ å°è¦æ¨¡ãƒãƒ¼ãƒ ï¼ˆæ™®é€šï¼‰
â”œâ”€ 1æ—¥50å›è³ªå• Ã— 30æ—¥ = æœˆ1,500å›
â”œâ”€ ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«ï¼šGPT-3.5-turbo
â””â”€ æœˆé¡æ–™é‡‘ï¼šç´„$10-15ï¼ˆ1,500å††-2,250å††ï¼‰ğŸ±ãŠå¼å½“2å€‹åˆ†

ğŸ­ æœ¬æ ¼é‹ç”¨ï¼ˆå¤šã‚ï¼‰
â”œâ”€ 1æ—¥200å›è³ªå• Ã— 30æ—¥ = æœˆ6,000å›
â”œâ”€ ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«ï¼šGPT-4oï¼ˆé«˜æ€§èƒ½ç‰ˆï¼‰
â””â”€ æœˆé¡æ–™é‡‘ï¼šç´„$30-50ï¼ˆ4,500å††-7,500å††ï¼‰ğŸ“šæœ¬æ•°å†Šåˆ†
```

#### **ğŸ’¡ æ–™é‡‘ã‚’æŠ‘ãˆã‚‹è¶…ç°¡å˜ãªæ–¹æ³•**

| ğŸ¯ ç¯€ç´„æ–¹æ³• | ğŸ’° ç¯€ç´„åŠ¹æœ | ğŸ”° åˆå¿ƒè€…ã§ã‚‚ç°¡å˜åº¦ |
|-------------|-------------|-------------------|
| **GPT-3.5-turboã‚’ä½¿ã†** | **90%ç¯€ç´„** | â­â­â­ (è¨­å®š1å›ã ã‘) |
| **è³ªå•ã‚’ç°¡æ½”ã«ã™ã‚‹** | **50%ç¯€ç´„** | â­â­â­ (æ„è­˜ã™ã‚‹ã ã‘) |
| **å›ç­”ã®é•·ã•ã‚’åˆ¶é™** | **30%ç¯€ç´„** | â­â­â˜† (è¨­å®šã§ç°¡å˜) |
| **ä¸è¦ãªè³ªå•ã‚’é¿ã‘ã‚‹** | **20%ç¯€ç´„** | â­â­â­ (å½“ç„¶ã®ã“ã¨) |

> ğŸ“‹ **åˆå¿ƒè€…ã«ãŠã™ã™ã‚ã®è¨­å®š**
> - ãƒ¢ãƒ‡ãƒ«ï¼š**GPT-3.5-turbo**ï¼ˆååˆ†é«˜æ€§èƒ½ã§å®‰ã„ï¼‰
> - æœˆé¡ä¸Šé™ï¼š**$20**ï¼ˆç´„3,000å††ï¼‰
> - ã“ã‚Œã§æœˆ1,000ã€œ2,000å›ã®è³ªå•ãŒå¯èƒ½ï¼

### ğŸ†˜ **å›°ã£ãŸæ™‚ã®Q&A**

#### **â“ ã‚ˆãã‚ã‚‹è³ªå•**

**Q1: è‹±èªã®ã‚µã‚¤ãƒˆã§ä¸å®‰ã§ã™...**
A1: å¤§ä¸ˆå¤«ï¼ã“ã®ã‚¬ã‚¤ãƒ‰ã®é€šã‚Šã«é€²ã‚ã‚Œã°ã€è‹±èªãŒèª­ã‚ãªãã¦ã‚‚ç¢ºå®Ÿã«ã§ãã¾ã™ã€‚é‡è¦ãªéƒ¨åˆ†ã¯å…¨ã¦æ—¥æœ¬èªã§èª¬æ˜ã—ã¦ã„ã¾ã™ã€‚

**Q2: ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚«ãƒ¼ãƒ‰ã®ç™»éŒ²ãŒæ€–ã„ã§ã™**
A2: OpenAIã¯ä¸–ç•Œä¸­ã§ä½¿ã‚ã‚Œã¦ã„ã‚‹å®‰å…¨ãªã‚µãƒ¼ãƒ“ã‚¹ã§ã™ã€‚ã•ã‚‰ã«ä¸Šé™è¨­å®šã‚’ã™ã‚‹ã“ã¨ã§ã€äºˆæƒ³å¤–ã®é«˜é¡è«‹æ±‚ã‚’é˜²ã’ã¾ã™ã€‚

**Q3: APIã‚­ãƒ¼ã‚’ç„¡ãã—ã¦ã—ã¾ã„ã¾ã—ãŸ**
A3: å¤§ä¸ˆå¤«ï¼ã„ã¤ã§ã‚‚æ–°ã—ãä½œã‚Šç›´ã›ã¾ã™ã€‚å¤ã„ã‚­ãƒ¼ã¯å‰Šé™¤ã—ã¦ã€æ–°ã—ã„ã‚­ãƒ¼ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

**Q4: æœ¬å½“ã«æœˆæ•°ç™¾å††ã§ä½¿ãˆã¾ã™ã‹ï¼Ÿ**
A4: ã¯ã„ï¼å€‹äººåˆ©ç”¨ãªã‚‰æœˆ500å††ä»¥ä¸‹ã§ååˆ†ä½¿ãˆã¾ã™ã€‚ä¸Šé™è¨­å®šã‚‚ã§ãã‚‹ã®ã§å®‰å¿ƒã§ã™ã€‚

### âœ… **å®Œäº†ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ**

ä»¥ä¸‹ãŒå…¨ã¦å®Œäº†ã—ãŸã‚‰æ¬¡ã«é€²ã‚“ã§ãã ã•ã„ï¼š

- [ ] OpenAIã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ä½œæˆã—ãŸ
- [ ] ãƒ¡ãƒ¼ãƒ«èªè¨¼ã‚’å®Œäº†ã—ãŸ
- [ ] APIã‚­ãƒ¼ã‚’ä½œæˆã—ã€å®‰å…¨ãªå ´æ‰€ã«ä¿å­˜ã—ãŸ
- [ ] æœˆé¡æ–™é‡‘ã®ä¸Šé™ã‚’è¨­å®šã—ãŸï¼ˆæ¨å¥¨ï¼š$20ï¼‰
- [ ] APIã‚­ãƒ¼ãŒã€Œsk-ã€ã§å§‹ã¾ã‚‹ã“ã¨ã‚’ç¢ºèªã—ãŸ

ğŸ‰ **ãŠç–²ã‚Œæ§˜ã§ã—ãŸï¼** ã“ã‚Œã§AIã¨ãŠè©±ã—ã™ã‚‹æº–å‚™ãŒæ•´ã„ã¾ã—ãŸï¼

ğŸš€ **æ¬¡ã®STEP**: [ğŸ“ è‡ªåˆ†ã®ãƒ•ã‚¡ã‚¤ãƒ«ç½®ãå ´ã‚’ä½œã‚ã†](#3-è‡ªåˆ†ã®ãƒ•ã‚¡ã‚¤ãƒ«ç½®ãå ´ã‚’ä½œã‚ã†)

---

## 3. ğŸ“ GitHubæº–å‚™ï¼ˆç”»é¢æ“ä½œã®ã¿ï¼‰

### 3.1 GitHubã‚¢ã‚«ã‚¦ãƒ³ãƒˆä½œæˆ

**æ—¢ã«ãŠæŒã¡ã®æ–¹ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ãã ã•ã„**

1. **GitHubå…¬å¼ã‚µã‚¤ãƒˆ**ã«ã‚¢ã‚¯ã‚»ã‚¹
   ```
   https://github.com/
   ```

2. **Sign up**ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã‚¢ã‚«ã‚¦ãƒ³ãƒˆä½œæˆ
   - ãƒ¦ãƒ¼ã‚¶ãƒ¼åï¼šåŠè§’è‹±æ•°å­—ï¼ˆä¾‹ï¼š`taro-yamada-2024`ï¼‰
   - ãƒ¡ãƒ¼ãƒ«ï¼šæ™®æ®µä½¿ç”¨ã™ã‚‹ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹
   - ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ï¼š8æ–‡å­—ä»¥ä¸Šã®å®‰å…¨ãªãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰

### 3.2 ãƒªãƒã‚¸ãƒˆãƒªä½œæˆãƒ»ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰

**æ–¹æ³•1: GitHub Desktopä½¿ç”¨ï¼ˆåˆå¿ƒè€…æ¨å¥¨ï¼‰**

1. **GitHub Desktop**ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ»ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
   ```
   https://desktop.github.com/
   ```

2. **ãƒªãƒã‚¸ãƒˆãƒªã‚’ä½œæˆ**
   - GitHub Desktopèµ·å‹•
   - ã€ŒCreate a new repositoryã€é¸æŠ
   - Name: `wiki-chatbot`
   - Local path: Wiki Chatbotãƒ•ã‚©ãƒ«ãƒ€ã‚’é¸æŠ
   - ã€ŒCreate repositoryã€ã‚’ã‚¯ãƒªãƒƒã‚¯

3. **ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**
   - ã€ŒPublish repositoryã€ã‚’ã‚¯ãƒªãƒƒã‚¯
   - ã€ŒKeep this code privateã€ã®ãƒã‚§ãƒƒã‚¯ã‚’å¤–ã™ï¼ˆç„¡æ–™ãƒ—ãƒ©ãƒ³ã®å ´åˆï¼‰
   - ã€ŒPublish repositoryã€ã§å®Œäº†

**æ–¹æ³•2: ãƒ–ãƒ©ã‚¦ã‚¶ã§ç›´æ¥ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆè¶…åˆå¿ƒè€…å‘ã‘ï¼‰**

1. **æ–°è¦ãƒªãƒã‚¸ãƒˆãƒªä½œæˆ**
   - GitHubãƒ­ã‚°ã‚¤ãƒ³å¾Œã€å³ä¸Šã®ã€Œ+ã€â†’ã€ŒNew repositoryã€
   - Repository name: `wiki-chatbot`
   - Public ã‚’é¸æŠ
   - ã€ŒCreate repositoryã€ã‚’ã‚¯ãƒªãƒƒã‚¯

2. **ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—**
   - ã€Œuploading an existing fileã€ã‚’ã‚¯ãƒªãƒƒã‚¯
   - Wiki Chatbotãƒ•ã‚©ãƒ«ãƒ€ã®å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—
   - Commit message: `Initial upload`
   - ã€ŒCommit changesã€ã‚’ã‚¯ãƒªãƒƒã‚¯

---

## 4. ğŸŒ ç„¡æ–™Webå…¬é–‹

### 4.1 Streamlit Cloud ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

1. **Streamlit Cloud**ã«ã‚¢ã‚¯ã‚»ã‚¹
   ```
   https://share.streamlit.io/
   ```

2. **GitHubã§ãƒ­ã‚°ã‚¤ãƒ³**
   - ã€ŒContinue with GitHubã€ã‚’ã‚¯ãƒªãƒƒã‚¯
   - GitHubèªè¨¼ã‚’å®Œäº†

3. **ã‚¢ãƒ—ãƒªã‚’ãƒ‡ãƒ—ãƒ­ã‚¤**
   - ã€ŒNew appã€ã‚’ã‚¯ãƒªãƒƒã‚¯
   - Repository: å…ˆã»ã©ä½œæˆã—ãŸ`wiki-chatbot`ã‚’é¸æŠ
   - Branch: `main`
   - Main file path: `app.py`
   - ã€ŒDeploy!ã€ã‚’ã‚¯ãƒªãƒƒã‚¯

### 4.2 API Keyè¨­å®šï¼ˆé‡è¦ï¼ï¼‰

**ãƒ‡ãƒ—ãƒ­ã‚¤å¾Œã€ã‚¢ãƒ—ãƒªãŒã‚¨ãƒ©ãƒ¼ã«ãªã£ãŸå ´åˆã®å¯¾å‡¦æ³•**

1. **ã‚¢ãƒ—ãƒªè¨­å®šç”»é¢ã«ã‚¢ã‚¯ã‚»ã‚¹**
   - ãƒ‡ãƒ—ãƒ­ã‚¤ã•ã‚ŒãŸã‚¢ãƒ—ãƒªç”»é¢å³ä¸Šã®ã€Œâš™ï¸ã€ã‚’ã‚¯ãƒªãƒƒã‚¯
   - ã€ŒSettingsã€ã‚’é¸æŠ

2. **Secretsè¨­å®š**
   - å·¦ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰ã€ŒSecretsã€ã‚’é¸æŠ
   - ä»¥ä¸‹ã‚’ã‚³ãƒ”ãƒšã—ã¦è²¼ã‚Šä»˜ã‘ï¼š

```toml
# ã‚ãªãŸã®OpenAI API Keyã«ç½®ãæ›ãˆã¦ãã ã•ã„
OPENAI_API_KEY = "sk-ã“ã“ã«ã‚ãªãŸã®APIã‚­ãƒ¼ã‚’è²¼ã‚Šä»˜ã‘"

# ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰è¨­å®šï¼ˆãŠå¥½ããªãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã«å¤‰æ›´ï¼‰
WEB_PASSWORD = "mypassword123"

# åŸºæœ¬è¨­å®šï¼ˆãã®ã¾ã¾ã§OKï¼‰
MAX_QUERIES_PER_SESSION = 100
SESSION_TIMEOUT_HOURS = 24
ENABLE_FILE_UPLOAD = true
MAX_FILE_SIZE_MB = 10
```

3. **è¨­å®šä¿å­˜**
   - ã€ŒSaveã€ã‚’ã‚¯ãƒªãƒƒã‚¯
   - ã‚¢ãƒ—ãƒªãŒè‡ªå‹•çš„ã«å†èµ·å‹•ã•ã‚Œã¾ã™

### 4.3 ãƒ‡ãƒ—ãƒ­ã‚¤æˆåŠŸç¢ºèª

âœ… **æˆåŠŸæ™‚ã®ç”»é¢**
- ãƒ­ã‚°ã‚¤ãƒ³ç”»é¢ãŒè¡¨ç¤ºã•ã‚Œã‚‹
- ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰å…¥åŠ›ã§ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆç”»é¢ã«é·ç§»
- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ãŒå‹•ä½œ

âŒ **å¤±æ•—æ™‚ã®å¯¾å‡¦**
- ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç¢ºèª
- [ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°](#10-ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°)ã‚’å‚ç…§

---

## 5. ğŸ›¡ï¸ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ°¸é ã«ä¿è­·

### 5.1 ğŸ“š ãƒ‡ãƒ¼ã‚¿æ°¸ç¶šåŒ–ã®é‡è¦æ€§ã‚’å®Œå…¨ç†è§£

#### ğŸš¨ ã€Œãªã‚“ã§ç§ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ¶ˆãˆã¡ã‚ƒã†ã®ï¼Ÿã€å•é¡Œ

**Streamlit Cloudã®ä»•çµ„ã¿**

```
ğŸ˜± å•é¡Œç™ºç”Ÿã®ãƒ‘ã‚¿ãƒ¼ãƒ³
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. ã‚ãªãŸãŒPDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰    â”‚ ğŸ“„
â”‚ 2. AIãŒãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’å­¦ç¿’ãƒ»è¨˜æ†¶       â”‚ ğŸ§ 
â”‚ 3. ç¿Œæ—¥ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã¨...              â”‚ ğŸ˜´
â”‚ 4. ã€Œãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€ã‚¨ãƒ©ãƒ¼  â”‚ âŒ
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ãªãœã“ã†ãªã‚‹ï¼Ÿ
ğŸ  Streamlit Cloud = ã€Œä¸€æ™‚çš„ãªä½œæ¥­å ´æ‰€ã€
   - ã‚¢ãƒ—ãƒªãŒä½¿ã‚ã‚Œãªã„ã¨ã€ŒãŠæƒé™¤ã€ãŒå…¥ã‚‹
   - ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€Œã‚´ãƒŸã€ã¨ã—ã¦å‰Šé™¤
   - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚‚å…¨éƒ¨ãƒªã‚»ãƒƒãƒˆ
```

#### âœ… æ°¸ç¶šåŒ–ã§è§£æ±ºã™ã‚‹å•é¡Œ

**1. ãƒ•ã‚¡ã‚¤ãƒ«æ¶ˆå¤±å•é¡Œã®å®Œå…¨è§£æ±º**
```
ğŸ”’ æ°¸ç¶šåŒ–å‰ vs æ°¸ç¶šåŒ–å¾Œ

ã€æ°¸ç¶šåŒ–å‰ã€‘ğŸ˜°
âŒ 1æ—¥å¾Œ: ãƒ•ã‚¡ã‚¤ãƒ«æ¶ˆå¤±
âŒ ã‚¢ãƒ—ãƒªå†èµ·å‹•: ãƒ‡ãƒ¼ã‚¿å…¨æ¶ˆå»
âŒ ä½¿ã†ãŸã³: å†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¿…è¦
âŒ å­¦ç¿’å†…å®¹: æ¯å›ã‚¼ãƒ­ã‹ã‚‰ã‚¹ã‚¿ãƒ¼ãƒˆ

ã€æ°¸ç¶šåŒ–å¾Œã€‘ğŸ˜
âœ… ä½•æ—¥å¾Œ: ãƒ•ã‚¡ã‚¤ãƒ«æ°¸ä¹…ä¿å­˜
âœ… ã‚¢ãƒ—ãƒªå†èµ·å‹•: ãƒ‡ãƒ¼ã‚¿ãã®ã¾ã¾
âœ… ä½¿ã†ãŸã³: ã™ãã«è³ªå•é–‹å§‹
âœ… å­¦ç¿’å†…å®¹: è“„ç©ã•ã‚Œã¦è³¢ããªã‚‹
```

**2. ä¼æ¥­åˆ©ç”¨ã§ã®å®‰å¿ƒæ„Ÿ**
```
ğŸ“Š ãƒ“ã‚¸ãƒã‚¹åˆ©ç”¨ã§ã®åŠ¹æœ

ğŸ¢ ä¼šç¤¾ã®é‡è¦æ–‡æ›¸ã‚’å®‰å¿ƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
   â”œâ”€ å¥‘ç´„æ›¸ã€ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã€FAQ
   â”œâ”€ ä¸€åº¦è¨­å®šã—ãŸã‚‰æ°¸ä¹…åˆ©ç”¨
   â””â”€ æ–°å…¥ç¤¾å“¡æ•™è‚²ã«ã‚‚æ´»ç”¨

ğŸ‘¥ ãƒãƒ¼ãƒ å…±æœ‰ã§ã®æ´»ç”¨
   â”œâ”€ éƒ¨ç½²ã®çŸ¥è­˜ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰
   â”œâ”€ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè³‡æ–™ã®å…±æœ‰
   â””â”€ ãƒŠãƒ¬ãƒƒã‚¸ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆ
```

### 5.2 ğŸ› ï¸ RAGãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ°¸ç¶šåŒ–ã‚·ã‚¹ãƒ†ãƒ ï¼ˆæŠ€è¡“è©³ç´°ï¼‰

#### 5.2.1 æ°¸ç¶šåŒ–ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å…¨ä½“å›³

```
ğŸ—ï¸ ãƒ‡ãƒ¼ã‚¿æ°¸ç¶šåŒ–ã®å…¨ä½“æ§‹é€ 

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ğŸŒ Streamlit Cloud                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚    ğŸ“± Web UI     â”‚      â”‚     ğŸ§  RAG Processing       â”‚ â”‚
â”‚  â”‚                 â”‚      â”‚                             â”‚ â”‚
â”‚  â”‚ â€¢ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ â”‚ â”€â”€â”€â”€â–¶ â”‚ â€¢ æ–‡æ›¸ãƒ™ã‚¯ãƒˆãƒ«åŒ–          â”‚ â”‚
â”‚  â”‚ â€¢ ãƒãƒ£ãƒƒãƒˆç”»é¢     â”‚      â”‚ â€¢ ChromaDBçŸ¥è­˜ãƒ™ãƒ¼ã‚¹     â”‚ â”‚
â”‚  â”‚ â€¢ ç®¡ç†ç”»é¢       â”‚      â”‚ â€¢ é¡ä¼¼æ–‡æ›¸æ¤œç´¢           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚           â”‚                              â”‚               â”‚
â”‚           â–¼                              â–¼               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚            ğŸ“¦ æ°¸ç¶šåŒ–ãƒ¬ã‚¤ãƒ¤ãƒ¼                          â”‚   â”‚
â”‚  â”‚                                                     â”‚   â”‚
â”‚  â”‚ â”œâ”€ ğŸ—ƒï¸ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ (data/products/)            â”‚   â”‚
â”‚  â”‚ â”‚   â”œâ”€ PDF, Word, ExcelåŸæœ¬                         â”‚   â”‚
â”‚  â”‚ â”‚   â”œâ”€ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ (.meta files)                     â”‚   â”‚
â”‚  â”‚ â”‚   â””â”€ ãƒ™ã‚¯ãƒˆãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ (.chroma/)               â”‚   â”‚
â”‚  â”‚                                                     â”‚   â”‚
â”‚  â”‚ â”œâ”€ ğŸ’¾ SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ (data/chatbot.db)           â”‚   â”‚
â”‚  â”‚ â”‚   â”œâ”€ ãƒãƒ£ãƒƒãƒˆå±¥æ­´ãƒ†ãƒ¼ãƒ–ãƒ«                          â”‚   â”‚
â”‚  â”‚ â”‚   â”œâ”€ ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯                        â”‚   â”‚
â”‚  â”‚ â”‚   â””â”€ ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿                        â”‚   â”‚
â”‚  â”‚                                                     â”‚   â”‚
â”‚  â”‚ â””â”€ ğŸ”„ è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ                         â”‚   â”‚
â”‚  â”‚     â”œâ”€ GitHub Actionså®šæœŸå®Ÿè¡Œ                        â”‚   â”‚
â”‚  â”‚     â””â”€ å·®åˆ†ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ©Ÿèƒ½                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚     ğŸ“ GitHub        â”‚
                  â”‚                     â”‚
                  â”‚ â€¢ data/ãƒ•ã‚©ãƒ«ãƒ€       â”‚
                  â”‚ â€¢ è‡ªå‹•ã‚³ãƒŸãƒƒãƒˆ        â”‚
                  â”‚ â€¢ ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†       â”‚
                  â”‚ â€¢ ç„¡æ–™100GB          â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 5.2.2 ChromaDBãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ°¸ç¶šåŒ–

**1. ãƒ™ã‚¯ãƒˆãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ°¸ç¶šåŒ–è¨­å®š**

```python
# utils/enhanced_rag_manager.py ã®æ°¸ç¶šåŒ–å¼·åŒ–ç‰ˆ

"""
RAGãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ°¸ç¶šåŒ–ã‚·ã‚¹ãƒ†ãƒ 
ChromaDB + ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ é€£æºã«ã‚ˆã‚‹å®Œå…¨ãƒ‡ãƒ¼ã‚¿ä¿è­·
"""

import chromadb
from chromadb.config import Settings
from pathlib import Path
import json
import hashlib
from datetime import datetime

class PersistentRAGManager:
    """æ°¸ç¶šåŒ–å¯¾å¿œRAGç®¡ç†ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        # æ°¸ç¶šåŒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
        self.persist_dir = Path("data/chroma_db")
        self.backup_dir = Path("data/chroma_backup")
        self.metadata_dir = Path("data/rag_metadata")

        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        for dir_path in [self.persist_dir, self.backup_dir, self.metadata_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)

        # ChromaDBæ°¸ç¶šåŒ–è¨­å®š
        self.chroma_client = chromadb.PersistentClient(
            path=str(self.persist_dir),
            settings=Settings(
                anonymized_telemetry=False,
                allow_reset=False  # æ°¸ç¶šåŒ–ãƒ‡ãƒ¼ã‚¿ã®èª¤å‰Šé™¤é˜²æ­¢
            )
        )

        # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ç®¡ç†
        self.collections = {}
        self._load_existing_collections()

    def _load_existing_collections(self):
        """æ—¢å­˜ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’å¾©å…ƒ"""
        try:
            # æ°¸ç¶šåŒ–ã•ã‚ŒãŸã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä¸€è¦§ã‚’å–å¾—
            existing_collections = self.chroma_client.list_collections()

            for collection_info in existing_collections:
                collection_name = collection_info.name
                collection = self.chroma_client.get_collection(name=collection_name)
                self.collections[collection_name] = collection
                print(f"âœ… ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å¾©å…ƒ: {collection_name}")

        except Exception as e:
            print(f"âš ï¸ ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å¾©å…ƒã‚¨ãƒ©ãƒ¼: {e}")

    def add_document_with_persistence(self, file_path: str, product_name: str):
        """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¿½åŠ  + å®Œå…¨æ°¸ç¶šåŒ–"""
        try:
            # 1. ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚·ãƒ¥ç”Ÿæˆï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯ç”¨ï¼‰
            file_hash = self._calculate_file_hash(file_path)
            doc_id = f"{product_name}_{file_hash}"

            # 2. æ—¢å­˜ãƒã‚§ãƒƒã‚¯
            if self._document_exists(product_name, doc_id):
                print(f"ğŸ“„ æ—¢å­˜æ–‡æ›¸ã®ãŸã‚å‡¦ç†ã‚¹ã‚­ãƒƒãƒ—: {file_path}")
                return True

            # 3. æ–‡æ›¸å‡¦ç†ï¼†ãƒ™ã‚¯ãƒˆãƒ«åŒ–
            chunks = self._process_document(file_path)
            embeddings = self._create_embeddings(chunks)

            # 4. ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å–å¾—/ä½œæˆ
            collection = self._get_or_create_collection(product_name)

            # 5. ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
            collection.add(
                documents=chunks,
                embeddings=embeddings,
                ids=[f"{doc_id}_chunk_{i}" for i in range(len(chunks))],
                metadatas=[{
                    "source": file_path,
                    "product": product_name,
                    "chunk_id": i,
                    "file_hash": file_hash,
                    "created_at": datetime.now().isoformat()
                } for i in range(len(chunks))]
            )

            # 6. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ°¸ç¶šåŒ–
            self._save_document_metadata(product_name, doc_id, file_path, chunks)

            # 7. è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
            self._create_incremental_backup(product_name)

            print(f"âœ… æ–‡æ›¸æ°¸ç¶šåŒ–å®Œäº†: {file_path}")
            return True

        except Exception as e:
            print(f"âŒ æ–‡æ›¸æ°¸ç¶šåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def _calculate_file_hash(self, file_path: str) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚·ãƒ¥è¨ˆç®—ï¼ˆé‡è¤‡æ¤œå‡ºç”¨ï¼‰"""
        hash_md5 = hashlib.md5()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()[:8]

    def _document_exists(self, product_name: str, doc_id: str) -> bool:
        """æ–‡æ›¸é‡è¤‡ãƒã‚§ãƒƒã‚¯"""
        metadata_file = self.metadata_dir / f"{product_name}_metadata.json"
        if metadata_file.exists():
            with open(metadata_file, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
                return doc_id in metadata.get("documents", {})
        return False

    def _save_document_metadata(self, product_name: str, doc_id: str, file_path: str, chunks: list):
        """æ–‡æ›¸ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ°¸ç¶šåŒ–"""
        metadata_file = self.metadata_dir / f"{product_name}_metadata.json"

        # æ—¢å­˜ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        if metadata_file.exists():
            with open(metadata_file, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
        else:
            metadata = {"documents": {}, "created_at": datetime.now().isoformat()}

        # æ–°è¦æ–‡æ›¸æƒ…å ±è¿½åŠ 
        metadata["documents"][doc_id] = {
            "file_path": file_path,
            "chunks_count": len(chunks),
            "processed_at": datetime.now().isoformat(),
            "file_size": Path(file_path).stat().st_size if Path(file_path).exists() else 0
        }
        metadata["last_updated"] = datetime.now().isoformat()

        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)

    def _create_incremental_backup(self, product_name: str):
        """å¢—åˆ†ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ"""
        try:
            backup_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_name = f"{product_name}_backup_{backup_timestamp}"

            # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿å–å¾—
            if product_name in self.collections:
                collection = self.collections[product_name]
                all_data = collection.get()

                # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
                backup_file = self.backup_dir / f"{backup_name}.json"
                with open(backup_file, 'w', encoding='utf-8') as f:
                    json.dump({
                        "collection_name": product_name,
                        "backup_timestamp": backup_timestamp,
                        "documents_count": len(all_data.get("documents", [])),
                        "data": all_data
                    }, f, ensure_ascii=False, indent=2)

                print(f"ğŸ”„ å¢—åˆ†ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ: {backup_name}")

        except Exception as e:
            print(f"âš ï¸ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")

    def get_storage_statistics(self):
        """ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸çµ±è¨ˆæƒ…å ±å–å¾—"""
        stats = {
            "total_collections": len(self.collections),
            "total_documents": 0,
            "storage_size_mb": 0,
            "collections_detail": {}
        }

        # ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡è¨ˆç®—
        for path in [self.persist_dir, self.metadata_dir, self.backup_dir]:
            for file_path in path.rglob("*"):
                if file_path.is_file():
                    stats["storage_size_mb"] += file_path.stat().st_size

        stats["storage_size_mb"] = round(stats["storage_size_mb"] / (1024 * 1024), 2)

        # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³è©³ç´°
        for name, collection in self.collections.items():
            try:
                data = collection.get()
                doc_count = len(data.get("documents", []))
                stats["total_documents"] += doc_count
                stats["collections_detail"][name] = {
                    "documents": doc_count,
                    "last_updated": "N/A"  # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å–å¾—å¯èƒ½
                }
            except:
                stats["collections_detail"][name] = {"documents": 0, "last_updated": "Error"}

        return stats
```

**2. è‡ªå‹•å¾©å…ƒã‚·ã‚¹ãƒ†ãƒ **

```python
# config/auto_recovery.py

"""
è‡ªå‹•ãƒ‡ãƒ¼ã‚¿å¾©å…ƒã‚·ã‚¹ãƒ†ãƒ 
ã‚¢ãƒ—ãƒªèµ·å‹•æ™‚ã®è‡ªå‹•ãƒ‡ãƒ¼ã‚¿å¾©æ—§æ©Ÿèƒ½
"""

class AutoRecoverySystem:
    """è‡ªå‹•å¾©å…ƒã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        self.data_dir = Path("data")
        self.recovery_log = Path("data/recovery.log")

    def startup_recovery_check(self):
        """èµ·å‹•æ™‚å¾©å…ƒãƒã‚§ãƒƒã‚¯"""
        print("ğŸ” ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯é–‹å§‹...")

        issues_found = []

        # 1. ChromaDBãƒ‡ãƒ¼ã‚¿ç¢ºèª
        chroma_dir = self.data_dir / "chroma_db"
        if not chroma_dir.exists():
            issues_found.append("ChromaDBãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä¸å­˜åœ¨")
            self._restore_chroma_from_backup()

        # 2. SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç¢ºèª
        db_file = self.data_dir / "chatbot.db"
        if not db_file.exists():
            issues_found.append("SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¸å­˜åœ¨")
            self._initialize_database()

        # 3. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
        inconsistencies = self._check_metadata_consistency()
        if inconsistencies:
            issues_found.extend(inconsistencies)

        # 4. å¾©å…ƒå®Ÿè¡Œ
        if issues_found:
            print(f"âš ï¸ {len(issues_found)}ä»¶ã®å•é¡Œã‚’æ¤œå‡ºã€è‡ªå‹•å¾©å…ƒå®Ÿè¡Œä¸­...")
            self._execute_recovery(issues_found)
        else:
            print("âœ… ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ç¢ºèªå®Œäº†")

    def _restore_chroma_from_backup(self):
        """ChromaDBãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰ã®å¾©å…ƒ"""
        backup_dir = self.data_dir / "chroma_backup"
        if backup_dir.exists():
            latest_backup = max(backup_dir.glob("*.json"), key=lambda p: p.stat().st_mtime, default=None)
            if latest_backup:
                print(f"ğŸ”„ ChromaDBå¾©å…ƒä¸­: {latest_backup.name}")
                # å¾©å…ƒå‡¦ç†å®Ÿè£…
```

### 5.2 æ°¸ç¶šåŒ–è¨­å®šï¼ˆ15åˆ†ã§å®Œäº†ï¼‰

#### 5.2.1 è‡ªå‹•æ°¸ç¶šåŒ–ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…

ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦æ°¸ç¶šåŒ–ã‚’å®Ÿç¾ã—ã¾ã™ï¼š

**1. `.gitignore`ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª**

Wiki Chatbotãƒ•ã‚©ãƒ«ãƒ€ã«`.gitignore`ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã€ä»¥ä¸‹ã‚’è¨˜è¿°ï¼š

```gitignore
# Python
__pycache__/
*.pyc
*.pyo
*.pyd
.Python

# ç§˜å¯†æƒ…å ±
.env
secrets.toml

# ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«
*.tmp
*.log

# æ°¸ç¶šåŒ–ã—ãŸã„ãƒ•ã‚¡ã‚¤ãƒ«ã¯GitHubã«å«ã‚ã‚‹
# data/ ãƒ•ã‚©ãƒ«ãƒ€ã¯æ°¸ç¶šåŒ–å¯¾è±¡
!data/
!data/**/*
```

**2. æ°¸ç¶šåŒ–ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ **

`config/persistent_storage.py`ã‚’ä½œæˆï¼š

```python
"""
æ°¸ç¶šåŒ–ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
GitHub + Streamlit Cloudé€£æºã«ã‚ˆã‚‹è‡ªå‹•ãƒ‡ãƒ¼ã‚¿ä¿å­˜
"""

import os
import json
import shutil
from pathlib import Path
from datetime import datetime
import streamlit as st

class PersistentStorage:
    """æ°¸ç¶šåŒ–ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ç®¡ç†ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.data_dir = Path("data")
        self.backup_dir = Path("data/backups")
        self.max_storage_mb = 100  # æœ€å¤§100MB

        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self.data_dir.mkdir(exist_ok=True)
        self.backup_dir.mkdir(exist_ok=True)

    def save_uploaded_file(self, uploaded_file, product_name: str):
        """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ°¸ç¶šåŒ–"""
        try:
            # è£½å“åˆ¥ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ
            product_dir = self.data_dir / "products" / product_name
            product_dir.mkdir(parents=True, exist_ok=True)

            # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            file_path = product_dir / uploaded_file.name
            with open(file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜
            self._save_metadata(file_path, uploaded_file)

            return str(file_path)

        except Exception as e:
            st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def _save_metadata(self, file_path: Path, uploaded_file):
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
        metadata = {
            "original_name": uploaded_file.name,
            "size": uploaded_file.size,
            "type": uploaded_file.type,
            "uploaded_at": datetime.now().isoformat(),
            "file_path": str(file_path)
        }

        metadata_path = file_path.with_suffix(f"{file_path.suffix}.meta")
        with open(metadata_path, "w", encoding="utf-8") as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)

    def get_storage_usage(self):
        """ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ä½¿ç”¨é‡ã‚’å–å¾—"""
        total_size = 0
        for file_path in self.data_dir.rglob("*"):
            if file_path.is_file():
                total_size += file_path.stat().st_size

        return total_size / (1024 * 1024)  # MBå¤‰æ›

    def cleanup_old_files(self, days_old: int = 30):
        """å¤ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•å‰Šé™¤"""
        cutoff_time = datetime.now().timestamp() - (days_old * 24 * 3600)

        for file_path in self.data_dir.rglob("*"):
            if file_path.is_file() and file_path.stat().st_mtime < cutoff_time:
                # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã«ç§»å‹•
                backup_path = self.backup_dir / file_path.name
                shutil.move(str(file_path), str(backup_path))

    def create_backup(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å…¨ä½“ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_name = f"backup_{timestamp}"

        shutil.make_archive(
            str(self.backup_dir / backup_name),
            "zip",
            str(self.data_dir)
        )

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
persistent_storage = PersistentStorage()
```

**3. ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®æ›´æ–°**

`utils/file_handler.py`ã«æ°¸ç¶šåŒ–æ©Ÿèƒ½ã‚’è¿½åŠ ï¼š

```python
# æ—¢å­˜ã®save_uploaded_fileé–¢æ•°ã‚’æ›´æ–°
def save_uploaded_file(self, uploaded_file, product_name: str):
    """æ°¸ç¶šåŒ–å¯¾å¿œã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜"""
    from config.persistent_storage import persistent_storage

    # æ°¸ç¶šåŒ–ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã«ä¿å­˜
    saved_path = persistent_storage.save_uploaded_file(uploaded_file, product_name)

    if saved_path:
        # RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«è¿½åŠ 
        success = self.rag_manager.add_document(
            file_path=saved_path,
            product_name=product_name
        )

        if success:
            st.success(f"âœ… {uploaded_file.name} ã‚’æ°¸ç¶šåŒ–ã—ã¾ã—ãŸ")
            return True

    return False
```

#### 5.2.2 è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—è¨­å®š

**GitHub Actionsè¨­å®š** (`.github/workflows/backup.yml`)

```yaml
name: Auto Backup
on:
  schedule:
    - cron: '0 2 * * *'  # æ¯æ—¥åˆå‰2æ™‚
  workflow_dispatch:

jobs:
  backup:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    - name: Create Backup
      run: |
        echo "$(date): Backup completed" >> data/backup_log.txt
    - name: Commit Backup
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add data/
        git commit -m "Auto backup: $(date)" || exit 0
        git push
```

### 5.3 å®¹é‡åˆ¶é™ç®¡ç†

```python
# config/storage_limits.py
STORAGE_LIMITS = {
    "max_total_mb": 100,        # åˆè¨ˆ100MB
    "max_file_mb": 10,          # ãƒ•ã‚¡ã‚¤ãƒ«1ã¤10MB
    "max_files_per_product": 50, # å•†å“æ¯50ãƒ•ã‚¡ã‚¤ãƒ«
    "auto_cleanup_days": 90,    # 90æ—¥ã§è‡ªå‹•å‰Šé™¤
    "backup_retention_days": 30  # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—30æ—¥ä¿å­˜
}
```

---

## 6. ğŸ’¬ ä¼šè©±å±¥æ­´ã‚’æ°¸ä¹…ä¿å­˜

### 6.1 ğŸ“Š ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³æ°¸ç¶šåŒ–ã®å…¨ä½“åƒ

#### ğŸŒŸ ã€Œãªãœä¼šè©±å±¥æ­´ãŒé‡è¦ãªã®ï¼Ÿã€å®Œå…¨è§£èª¬

**1. ä¼šè©±ã®ç¶™ç¶šæ€§ç¢ºä¿**
```
ğŸ—£ï¸ è‡ªç„¶ãªä¼šè©±ä½“é¨“ã®å®Ÿç¾

âŒ å±¥æ­´ãªã—ã®å ´åˆ:
  ãƒ¦ãƒ¼ã‚¶ãƒ¼: ã€Œå…ˆã»ã©ã®ä»¶ã«ã¤ã„ã¦...ã€
  AI: ã€Œã™ã¿ã¾ã›ã‚“ã€è¦šãˆã¦ã„ã¾ã›ã‚“ã€ğŸ˜°

âœ… å±¥æ­´ã‚ã‚Šã®å ´åˆ:
  ãƒ¦ãƒ¼ã‚¶ãƒ¼: ã€Œå…ˆã»ã©ã®ä»¶ã«ã¤ã„ã¦...ã€
  AI: ã€Œã¯ã„ã€â—‹â—‹ã®ä»¶ã§ã™ã­ï¼ã€ğŸ˜Š
```

**2. å­¦ç¿’åŠ¹æœã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Š**
```
ğŸ“ˆ ã‚·ã‚¹ãƒ†ãƒ æ”¹å–„ã¸ã®æ´»ç”¨

âœ… è³ªå•ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
   â”œâ”€ ã‚ˆãèã‹ã‚Œã‚‹è³ªå•ã®ç‰¹å®š
   â”œâ”€ å›ç­”ç²¾åº¦ã®æ¸¬å®š
   â””â”€ ã‚·ã‚¹ãƒ†ãƒ æ”¹å–„ç‚¹ã®ç™ºè¦‹

âœ… ãƒ¦ãƒ¼ã‚¶ãƒ¼æº€è¶³åº¦åˆ†æ
   â”œâ”€ æº€è¶³åº¦è©•ä¾¡ã®è“„ç©
   â”œâ”€ å•é¡Œã®ã‚ã‚‹å›ç­”ã®ç‰¹å®š
   â””â”€ AIå›ç­”å“è³ªã®å‘ä¸Š

âœ… é‹ç”¨æœ€é©åŒ–
   â”œâ”€ ãƒ”ãƒ¼ã‚¯æ™‚é–“ã®æŠŠæ¡
   â”œâ”€ ãƒªã‚½ãƒ¼ã‚¹é…åˆ†ã®æœ€é©åŒ–
   â””â”€ ã‚³ã‚¹ãƒˆåŠ¹ç‡ã®æ”¹å–„
```

**3. ä¼æ¥­åˆ©ç”¨ã§ã®ä¾¡å€¤**
```
ğŸ¢ ãƒ“ã‚¸ãƒã‚¹æ´»ç”¨ä¾‹

ğŸ“‹ çŸ¥è­˜è“„ç©
   â”œâ”€ ç¤¾å†…Q&Aã®æ§‹ç¯‰
   â”œâ”€ ã‚ˆãã‚ã‚‹è³ªå•ã®æ•´ç†
   â””â”€ æ–°äººæ•™è‚²è³‡æ–™ä½œæˆ

ğŸ“Š åˆ†æãƒ¬ãƒãƒ¼ãƒˆ
   â”œâ”€ éƒ¨ç½²åˆ¥åˆ©ç”¨çŠ¶æ³
   â”œâ”€ å•ã„åˆã‚ã›å‚¾å‘åˆ†æ
   â””â”€ æ¥­å‹™åŠ¹ç‡åŒ–ã®æŒ‡æ¨™

ğŸ” ç›£æŸ»å¯¾å¿œ
   â”œâ”€ æƒ…å ±ã‚¢ã‚¯ã‚»ã‚¹å±¥æ­´
   â”œâ”€ ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ç¢ºèª
   â””â”€ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£åˆ†æ
```

### 6.2 ğŸ—„ï¸ å®Œå…¨æ°¸ç¶šåŒ–ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚·ã‚¹ãƒ†ãƒ 

#### 6.2.1 å¤šå±¤ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹é€ 

```
ğŸ—ï¸ ãƒ‡ãƒ¼ã‚¿æ°¸ç¶šåŒ–ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ğŸ’¾ æ°¸ç¶šåŒ–ãƒ‡ãƒ¼ã‚¿ç®¡ç†å±¤                   â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  ğŸ—£ï¸ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ   â”‚  â”‚        ğŸ“Š åˆ†æãƒ»çµ±è¨ˆãƒ‡ãƒ¼ã‚¿        â”‚ â”‚
â”‚  â”‚   ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ â”‚  â”‚                                 â”‚ â”‚
â”‚  â”‚                 â”‚  â”‚ â€¢ åˆ©ç”¨çµ±è¨ˆãƒ†ãƒ¼ãƒ–ãƒ«               â”‚ â”‚
â”‚  â”‚ â€¢ ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†   â”‚  â”‚ â€¢ æº€è¶³åº¦åˆ†æãƒ†ãƒ¼ãƒ–ãƒ«             â”‚ â”‚
â”‚  â”‚ â€¢ ä¼šè©±å±¥æ­´       â”‚  â”‚ â€¢ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«           â”‚ â”‚
â”‚  â”‚ â€¢ ãƒ¦ãƒ¼ã‚¶ãƒ¼çŠ¶æ…‹    â”‚  â”‚ â€¢ æœˆæ¬¡/é€±æ¬¡é›†è¨ˆãƒ†ãƒ¼ãƒ–ãƒ«           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚           â”‚                              â”‚               â”‚
â”‚           â–¼                              â–¼               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚           ğŸ—ƒï¸ SQLiteæ°¸ç¶šåŒ–ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹                â”‚   â”‚
â”‚  â”‚                                                     â”‚   â”‚
â”‚  â”‚ ğŸ“‹ chat_history              ğŸ’­ user_feedback        â”‚   â”‚
â”‚  â”‚  â”œâ”€ conversation_id           â”œâ”€ feedback_id         â”‚   â”‚
â”‚  â”‚  â”œâ”€ user_message             â”œâ”€ satisfaction_score  â”‚   â”‚
â”‚  â”‚  â”œâ”€ ai_response              â”œâ”€ improvement_note    â”‚   â”‚
â”‚  â”‚  â”œâ”€ context_used             â”œâ”€ feature_request     â”‚   â”‚
â”‚  â”‚  â”œâ”€ response_time            â””â”€ timestamp           â”‚   â”‚
â”‚  â”‚  â”œâ”€ satisfaction_score                              â”‚   â”‚
â”‚  â”‚  â””â”€ metadata (JSON)          ğŸ”— session_management  â”‚   â”‚
â”‚  â”‚                               â”œâ”€ session_id         â”‚   â”‚
â”‚  â”‚ ğŸ“ file_interactions          â”œâ”€ user_identifier    â”‚   â”‚
â”‚  â”‚  â”œâ”€ file_access_log           â”œâ”€ login_time         â”‚   â”‚
â”‚  â”‚  â”œâ”€ upload_history            â”œâ”€ last_activity      â”‚   â”‚
â”‚  â”‚  â”œâ”€ download_requests         â””â”€ session_duration   â”‚   â”‚
â”‚  â”‚  â””â”€ permission_log                                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                             â”‚
â”‚                              â–¼                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              ğŸ”„ è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ»å¾©å…ƒ                â”‚   â”‚
â”‚  â”‚                                                     â”‚   â”‚
â”‚  â”‚ â€¢ æ¯æ—¥è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—        â€¢ éšœå®³æ™‚è‡ªå‹•å¾©å…ƒ         â”‚   â”‚
â”‚  â”‚ â€¢ å·®åˆ†ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—           â€¢ ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯     â”‚   â”‚
â”‚  â”‚ â€¢ ä¸–ä»£ç®¡ç†ï¼ˆ30æ—¥é–“ï¼‰         â€¢ ç·Šæ€¥æ™‚æ‰‹å‹•å¾©å…ƒ         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 6.2.2 é«˜åº¦ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆ

**å®Œå…¨ç‰ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒ** (`config/database.py`)

```python
"""
åŒ…æ‹¬çš„ãƒ‡ãƒ¼ã‚¿æ°¸ç¶šåŒ–ã‚·ã‚¹ãƒ†ãƒ 
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³å®Œå…¨è¨˜éŒ²ãƒ»åˆ†æã‚·ã‚¹ãƒ†ãƒ 
"""

import sqlite3
import json
import hashlib
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import logging

class ComprehensiveDatabase:
    """åŒ…æ‹¬çš„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        self.db_path = Path("data/chatbot_comprehensive.db")
        self.backup_dir = Path("data/db_backups")
        self.db_path.parent.mkdir(exist_ok=True)
        self.backup_dir.mkdir(exist_ok=True)

        # ãƒ­ã‚°è¨­å®š
        self.logger = self._setup_logging()

        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
        self._init_comprehensive_database()

        # å®šæœŸãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—è¨­å®š
        self._setup_auto_backup()

    def _init_comprehensive_database(self):
        """åŒ…æ‹¬çš„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹é€ ã®åˆæœŸåŒ–"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("PRAGMA foreign_keys = ON")  # å¤–éƒ¨ã‚­ãƒ¼åˆ¶ç´„æœ‰åŠ¹åŒ–

            # 1. è©³ç´°ä¼šè©±å±¥æ­´ãƒ†ãƒ¼ãƒ–ãƒ«
            conn.execute("""
                CREATE TABLE IF NOT EXISTS conversation_history (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    conversation_id TEXT NOT NULL,
                    session_id TEXT NOT NULL,
                    timestamp TEXT NOT NULL,

                    -- ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±
                    user_ip TEXT,
                    user_agent TEXT,
                    user_session_duration INTEGER,

                    -- å¯¾è©±å†…å®¹
                    product_name TEXT NOT NULL,
                    user_message TEXT NOT NULL,
                    user_message_length INTEGER,
                    ai_response TEXT NOT NULL,
                    ai_response_length INTEGER,

                    -- RAGæƒ…å ±
                    sources_used TEXT,  -- JSONå½¢å¼
                    chunks_retrieved INTEGER,
                    similarity_scores TEXT,  -- JSONå½¢å¼

                    -- å‡¦ç†è©³ç´°
                    llm_model_used TEXT,
                    prompt_style TEXT,
                    processing_time_ms INTEGER,
                    tokens_used INTEGER,
                    cost_estimate REAL,

                    -- æº€è¶³åº¦ãƒ»è©•ä¾¡
                    satisfaction_score INTEGER,
                    user_feedback_immediate TEXT,
                    response_quality_score REAL,

                    -- ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
                    error_occurred BOOLEAN DEFAULT FALSE,
                    error_message TEXT,
                    retry_count INTEGER DEFAULT 0,
                    metadata TEXT,  -- JSONå½¢å¼

                    created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                    updated_at TEXT DEFAULT CURRENT_TIMESTAMP
                )
            """)

            # 2. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ãƒ†ãƒ¼ãƒ–ãƒ«
            conn.execute("""
                CREATE TABLE IF NOT EXISTS user_sessions (
                    session_id TEXT PRIMARY KEY,
                    start_time TEXT NOT NULL,
                    end_time TEXT,
                    user_ip TEXT,
                    user_agent TEXT,

                    -- ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆ
                    total_messages INTEGER DEFAULT 0,
                    total_files_uploaded INTEGER DEFAULT 0,
                    total_time_spent_minutes INTEGER DEFAULT 0,
                    products_accessed TEXT,  -- JSONé…åˆ—

                    -- è¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³
                    peak_activity_hour INTEGER,
                    average_response_time_ms REAL,
                    satisfaction_average REAL,

                    -- ã‚»ãƒƒã‚·ãƒ§ãƒ³å“è³ª
                    successful_interactions INTEGER DEFAULT 0,
                    failed_interactions INTEGER DEFAULT 0,
                    session_quality_score REAL,

                    created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                    last_updated TEXT DEFAULT CURRENT_TIMESTAMP
                )
            """)

            # 3. ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œå±¥æ­´ãƒ†ãƒ¼ãƒ–ãƒ«
            conn.execute("""
                CREATE TABLE IF NOT EXISTS file_interaction_log (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    session_id TEXT NOT NULL,
                    action_type TEXT NOT NULL,  -- upload, access, delete, etc.

                    -- ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±
                    product_name TEXT NOT NULL,
                    file_name TEXT NOT NULL,
                    file_path TEXT,
                    file_size_bytes INTEGER,
                    file_type TEXT,
                    file_hash TEXT,  -- é‡è¤‡æ¤œå‡ºç”¨

                    -- å‡¦ç†è©³ç´°
                    processing_time_ms INTEGER,
                    success BOOLEAN NOT NULL,
                    error_message TEXT,
                    chunks_created INTEGER,

                    -- ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡
                    user_ip TEXT,
                    permission_level TEXT,
                    access_reason TEXT,

                    timestamp TEXT DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (session_id) REFERENCES user_sessions (session_id)
                )
            """)

            # 4. è©³ç´°ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ†ãƒ¼ãƒ–ãƒ«
            conn.execute("""
                CREATE TABLE IF NOT EXISTS user_feedback_detailed (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    conversation_id TEXT NOT NULL,
                    session_id TEXT NOT NULL,

                    -- æº€è¶³åº¦è©³ç´°
                    overall_satisfaction INTEGER,  -- 1-5ã‚¹ã‚±ãƒ¼ãƒ«
                    response_accuracy INTEGER,
                    response_speed INTEGER,
                    response_helpfulness INTEGER,
                    ui_experience INTEGER,

                    -- ãƒ•ãƒªãƒ¼ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
                    positive_feedback TEXT,
                    improvement_suggestions TEXT,
                    feature_requests TEXT,
                    bug_reports TEXT,

                    -- åˆ†é¡ãƒ»ã‚¿ã‚°
                    feedback_category TEXT,
                    priority_level TEXT,
                    status TEXT DEFAULT 'new',  -- new, reviewed, addressed

                    created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (conversation_id) REFERENCES conversation_history (conversation_id)
                )
            """)

            # 5. ã‚·ã‚¹ãƒ†ãƒ åˆ©ç”¨çµ±è¨ˆãƒ†ãƒ¼ãƒ–ãƒ«
            conn.execute("""
                CREATE TABLE IF NOT EXISTS usage_analytics (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    date TEXT NOT NULL,  -- YYYY-MM-DDå½¢å¼

                    -- åˆ©ç”¨é‡çµ±è¨ˆ
                    total_sessions INTEGER DEFAULT 0,
                    total_conversations INTEGER DEFAULT 0,
                    total_files_uploaded INTEGER DEFAULT 0,
                    total_users INTEGER DEFAULT 0,

                    -- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ
                    avg_response_time_ms REAL,
                    avg_satisfaction_score REAL,
                    success_rate REAL,
                    error_rate REAL,

                    -- ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡
                    total_tokens_used INTEGER DEFAULT 0,
                    total_cost_estimate REAL,
                    storage_used_mb REAL,

                    -- ãƒ”ãƒ¼ã‚¯æ™‚é–“åˆ†æ
                    peak_hour INTEGER,
                    peak_hour_sessions INTEGER,

                    created_at TEXT DEFAULT CURRENT_TIMESTAMP
                )
            """)

            # 6. ã‚¨ãƒ©ãƒ¼ãƒ»ãƒ­ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«
            conn.execute("""
                CREATE TABLE IF NOT EXISTS system_logs (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT NOT NULL,
                    log_level TEXT NOT NULL,  -- DEBUG, INFO, WARNING, ERROR, CRITICAL

                    -- ã‚¨ãƒ©ãƒ¼è©³ç´°
                    component TEXT,  -- RAG, LLM, Database, etc.
                    error_type TEXT,
                    error_message TEXT,
                    stack_trace TEXT,

                    -- ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
                    session_id TEXT,
                    user_ip TEXT,
                    affected_operation TEXT,

                    -- è§£æ±ºçŠ¶æ³
                    resolution_status TEXT DEFAULT 'new',
                    resolution_notes TEXT,
                    resolved_at TEXT,

                    created_at TEXT DEFAULT CURRENT_TIMESTAMP
                )
            """)

    def save_comprehensive_interaction(self, interaction_data: Dict) -> bool:
        """åŒ…æ‹¬çš„ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ä¿å­˜"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                # 1. ä¼šè©±å±¥æ­´ä¿å­˜
                conn.execute("""
                    INSERT INTO conversation_history (
                        conversation_id, session_id, timestamp, user_ip, user_agent,
                        product_name, user_message, user_message_length,
                        ai_response, ai_response_length,
                        sources_used, chunks_retrieved, similarity_scores,
                        llm_model_used, prompt_style, processing_time_ms,
                        tokens_used, cost_estimate, satisfaction_score,
                        metadata
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    interaction_data.get('conversation_id'),
                    interaction_data.get('session_id'),
                    datetime.now().isoformat(),
                    interaction_data.get('user_ip'),
                    interaction_data.get('user_agent'),
                    interaction_data.get('product_name'),
                    interaction_data.get('user_message'),
                    len(interaction_data.get('user_message', '')),
                    interaction_data.get('ai_response'),
                    len(interaction_data.get('ai_response', '')),
                    json.dumps(interaction_data.get('sources_used', [])),
                    interaction_data.get('chunks_retrieved', 0),
                    json.dumps(interaction_data.get('similarity_scores', [])),
                    interaction_data.get('llm_model_used'),
                    interaction_data.get('prompt_style'),
                    interaction_data.get('processing_time_ms'),
                    interaction_data.get('tokens_used'),
                    interaction_data.get('cost_estimate'),
                    interaction_data.get('satisfaction_score'),
                    json.dumps(interaction_data.get('metadata', {}))
                ))

                # 2. ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆæ›´æ–°
                self._update_session_stats(
                    conn,
                    interaction_data.get('session_id'),
                    interaction_data
                )

                conn.commit()
                return True

        except Exception as e:
            self.logger.error(f"åŒ…æ‹¬çš„ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def _update_session_stats(self, conn, session_id: str, interaction_data: Dict):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆã®æ›´æ–°"""
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³å­˜åœ¨ç¢ºèª
        cursor = conn.execute(
            "SELECT total_messages FROM user_sessions WHERE session_id = ?",
            (session_id,)
        )
        result = cursor.fetchone()

        if result:
            # æ—¢å­˜ã‚»ãƒƒã‚·ãƒ§ãƒ³æ›´æ–°
            conn.execute("""
                UPDATE user_sessions SET
                    total_messages = total_messages + 1,
                    last_updated = ?,
                    satisfaction_average = (
                        SELECT AVG(satisfaction_score)
                        FROM conversation_history
                        WHERE session_id = ? AND satisfaction_score IS NOT NULL
                    )
                WHERE session_id = ?
            """, (datetime.now().isoformat(), session_id, session_id))
        else:
            # æ–°è¦ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ
            conn.execute("""
                INSERT INTO user_sessions (
                    session_id, start_time, user_ip, user_agent, total_messages
                ) VALUES (?, ?, ?, ?, 1)
            """, (
                session_id,
                datetime.now().isoformat(),
                interaction_data.get('user_ip'),
                interaction_data.get('user_agent')
            ))

    def get_comprehensive_analytics(self, date_range: int = 30) -> Dict:
        """åŒ…æ‹¬çš„åˆ†æãƒ‡ãƒ¼ã‚¿å–å¾—"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                # æŒ‡å®šæœŸé–“ã®ãƒ‡ãƒ¼ã‚¿å–å¾—
                cutoff_date = (datetime.now() - timedelta(days=date_range)).isoformat()

                analytics = {}

                # 1. åŸºæœ¬çµ±è¨ˆ
                cursor = conn.execute("""
                    SELECT
                        COUNT(*) as total_conversations,
                        COUNT(DISTINCT session_id) as unique_sessions,
                        AVG(satisfaction_score) as avg_satisfaction,
                        AVG(processing_time_ms) as avg_processing_time,
                        SUM(tokens_used) as total_tokens
                    FROM conversation_history
                    WHERE created_at >= ?
                """, (cutoff_date,))

                basic_stats = cursor.fetchone()
                analytics['basic_stats'] = {
                    'total_conversations': basic_stats[0],
                    'unique_sessions': basic_stats[1],
                    'avg_satisfaction': round(basic_stats[2] or 0, 2),
                    'avg_processing_time_ms': round(basic_stats[3] or 0, 2),
                    'total_tokens': basic_stats[4] or 0
                }

                # 2. å•†å“åˆ¥åˆ©ç”¨çŠ¶æ³
                cursor = conn.execute("""
                    SELECT
                        product_name,
                        COUNT(*) as conversation_count,
                        AVG(satisfaction_score) as avg_satisfaction
                    FROM conversation_history
                    WHERE created_at >= ?
                    GROUP BY product_name
                    ORDER BY conversation_count DESC
                """, (cutoff_date,))

                analytics['product_usage'] = [
                    {
                        'product': row[0],
                        'conversations': row[1],
                        'satisfaction': round(row[2] or 0, 2)
                    }
                    for row in cursor.fetchall()
                ]

                # 3. æ™‚é–“å¸¯åˆ¥åˆ©ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³
                cursor = conn.execute("""
                    SELECT
                        strftime('%H', created_at) as hour,
                        COUNT(*) as conversation_count
                    FROM conversation_history
                    WHERE created_at >= ?
                    GROUP BY strftime('%H', created_at)
                    ORDER BY hour
                """, (cutoff_date,))

                analytics['hourly_usage'] = {
                    row[0]: row[1] for row in cursor.fetchall()
                }

                return analytics

        except Exception as e:
            self.logger.error(f"åˆ†æãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {}

    def export_data_for_analysis(self, format_type: str = 'csv') -> str:
        """åˆ†æç”¨ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            export_dir = Path("data/exports")
            export_dir.mkdir(exist_ok=True)

            if format_type == 'csv':
                import csv
                export_file = export_dir / f"chat_analytics_{timestamp}.csv"

                with sqlite3.connect(self.db_path) as conn:
                    cursor = conn.execute("""
                        SELECT
                            conversation_id, session_id, timestamp, product_name,
                            user_message_length, ai_response_length,
                            satisfaction_score, processing_time_ms, tokens_used
                        FROM conversation_history
                        ORDER BY timestamp DESC
                    """)

                    with open(export_file, 'w', newline='', encoding='utf-8') as csvfile:
                        writer = csv.writer(csvfile)
                        writer.writerow([
                            'Conversation ID', 'Session ID', 'Timestamp', 'Product',
                            'User Message Length', 'AI Response Length',
                            'Satisfaction', 'Processing Time (ms)', 'Tokens Used'
                        ])
                        writer.writerows(cursor.fetchall())

                return str(export_file)

        except Exception as e:
            self.logger.error(f"ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return ""
```

#### 6.2.3 ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

**ç®¡ç†ç”»é¢å‘ã‘åˆ†ææ©Ÿèƒ½** (`pages/analytics_dashboard.py`)

```python
"""
ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³å¯è¦–åŒ–ã‚·ã‚¹ãƒ†ãƒ 
"""

import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
import pandas as pd
from datetime import datetime, timedelta

def render_analytics_dashboard():
    """åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°"""

    st.title("ğŸ“Š ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")

    # ãƒ‡ãƒ¼ã‚¿å–å¾—
    analytics_data = get_comprehensive_analytics()

    # 1. KPIè¡¨ç¤º
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric(
            "ç·ä¼šè©±æ•°",
            analytics_data['basic_stats']['total_conversations'],
            delta=f"+{get_daily_growth('conversations')}%"
        )

    with col2:
        st.metric(
            "å¹³å‡æº€è¶³åº¦",
            f"{analytics_data['basic_stats']['avg_satisfaction']}/5.0",
            delta=f"+{get_satisfaction_trend()}%"
        )

    with col3:
        st.metric(
            "ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚»ãƒƒã‚·ãƒ§ãƒ³",
            analytics_data['basic_stats']['unique_sessions'],
            delta=f"+{get_daily_growth('sessions')}%"
        )

    with col4:
        st.metric(
            "å¹³å‡å¿œç­”æ™‚é–“",
            f"{analytics_data['basic_stats']['avg_processing_time_ms']:.0f}ms",
            delta=f"-{get_performance_improvement()}%"
        )

    # 2. æ™‚é–“å¸¯åˆ¥åˆ©ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³
    st.subheader("â° æ™‚é–“å¸¯åˆ¥åˆ©ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³")

    hourly_data = analytics_data.get('hourly_usage', {})
    hours = list(range(24))
    usage_counts = [hourly_data.get(f"{h:02d}", 0) for h in hours]

    fig_hourly = px.bar(
        x=hours,
        y=usage_counts,
        title="æ™‚é–“å¸¯åˆ¥ä¼šè©±æ•°",
        labels={'x': 'æ™‚é–“', 'y': 'ä¼šè©±æ•°'}
    )
    st.plotly_chart(fig_hourly, use_container_width=True)

    # 3. å•†å“åˆ¥åˆ©ç”¨çŠ¶æ³
    st.subheader("ğŸ“¦ å•†å“åˆ¥åˆ©ç”¨çŠ¶æ³")

    product_data = analytics_data.get('product_usage', [])
    if product_data:
        df_products = pd.DataFrame(product_data)

        fig_products = px.pie(
            df_products,
            values='conversations',
            names='product',
            title="å•†å“åˆ¥ä¼šè©±åˆ†å¸ƒ"
        )
        st.plotly_chart(fig_products, use_container_width=True)

    # 4. æº€è¶³åº¦ãƒˆãƒ¬ãƒ³ãƒ‰
    st.subheader("ğŸ˜Š æº€è¶³åº¦ãƒˆãƒ¬ãƒ³ãƒ‰")

    satisfaction_trend = get_satisfaction_trend_data()
    if satisfaction_trend:
        fig_satisfaction = px.line(
            satisfaction_trend,
            x='date',
            y='avg_satisfaction',
            title="æ—¥åˆ¥å¹³å‡æº€è¶³åº¦",
            labels={'date': 'æ—¥ä»˜', 'avg_satisfaction': 'å¹³å‡æº€è¶³åº¦'}
        )
        st.plotly_chart(fig_satisfaction, use_container_width=True)
```

### 6.3 ğŸ”§ å®Ÿè£…æ‰‹é †ï¼ˆã‚³ãƒ”ãƒšã§å®Œäº†ï¼‰

#### 6.3.1 ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ°¸ç¶šåŒ–ã®å®Ÿè£…

**1. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°**

`config/settings.py`ã«ä»¥ä¸‹ã‚’è¿½åŠ ï¼š

```python
# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ°¸ç¶šåŒ–è¨­å®š
DATABASE_CONFIG = {
    "enable_persistence": True,
    "db_path": "data/chatbot_comprehensive.db",
    "backup_interval_hours": 24,
    "max_backup_files": 30,
    "auto_vacuum": True,
    "analytics_enabled": True
}

# ãƒ‡ãƒ¼ã‚¿ä¿æŒãƒãƒªã‚·ãƒ¼
DATA_RETENTION_POLICY = {
    "chat_history_days": 365,      # 1å¹´é–“ä¿æŒ
    "user_sessions_days": 180,     # 6ãƒ¶æœˆä¿æŒ
    "system_logs_days": 90,        # 3ãƒ¶æœˆä¿æŒ
    "analytics_data_days": 730     # 2å¹´é–“ä¿æŒ
}
```

**2. ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çµ±åˆ**

`app.py`ã«æ°¸ç¶šåŒ–æ©Ÿèƒ½ã‚’çµ±åˆï¼š

```python
import streamlit as st
from config.database import ComprehensiveDatabase
from utils.session_manager import SessionManager
import uuid
from datetime import datetime

# ã‚¢ãƒ—ãƒªèµ·å‹•æ™‚ã®åˆæœŸåŒ–
@st.cache_resource
def initialize_persistent_database():
    """æ°¸ç¶šåŒ–ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–"""
    return ComprehensiveDatabase()

def save_interaction_with_persistence(user_message, ai_response, product_name):
    """ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã®æ°¸ç¶šåŒ–ä¿å­˜"""

    db = initialize_persistent_database()
    session_manager = SessionManager()

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±å–å¾—
    session_id = session_manager.get_session_id()

    # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿æ§‹ç¯‰
    interaction_data = {
        'conversation_id': str(uuid.uuid4()),
        'session_id': session_id,
        'user_ip': st.context.headers.get('x-forwarded-for', 'unknown'),
        'user_agent': st.context.headers.get('user-agent', 'unknown'),
        'product_name': product_name,
        'user_message': user_message,
        'ai_response': ai_response,
        'llm_model_used': st.session_state.get('current_llm_model', 'unknown'),
        'prompt_style': st.session_state.get('prompt_style', 'standard'),
        'processing_time_ms': st.session_state.get('last_response_time', 0),
        'tokens_used': st.session_state.get('tokens_used', 0),
        'sources_used': st.session_state.get('sources_used', []),
        'chunks_retrieved': len(st.session_state.get('sources_used', [])),
        'metadata': {
            'timestamp': datetime.now().isoformat(),
            'page': 'chat',
            'feature_flags': st.session_state.get('feature_flags', {})
        }
    }

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜
    success = db.save_comprehensive_interaction(interaction_data)

    if success:
        st.session_state['last_interaction_saved'] = True

    return success
```

**3. ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯æ©Ÿèƒ½ã®çµ±åˆ**

```python
def save_user_feedback(conversation_id, satisfaction_data):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®ä¿å­˜"""

    db = initialize_persistent_database()

    with sqlite3.connect(db.db_path) as conn:
        conn.execute("""
            INSERT INTO user_feedback_detailed (
                conversation_id, session_id, overall_satisfaction,
                response_accuracy, response_speed, response_helpfulness,
                positive_feedback, improvement_suggestions
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            conversation_id,
            st.session_state.get('session_id'),
            satisfaction_data.get('overall', 3),
            satisfaction_data.get('accuracy', 3),
            satisfaction_data.get('speed', 3),
            satisfaction_data.get('helpfulness', 3),
            satisfaction_data.get('positive_feedback', ''),
            satisfaction_data.get('improvements', '')
        ))

# ãƒãƒ£ãƒƒãƒˆç”»é¢ã«ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯æ©Ÿèƒ½è¿½åŠ 
def render_feedback_widget():
    """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã®ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°"""

    if 'last_ai_response' in st.session_state:
        st.markdown("---")
        st.subheader("ğŸ“ ã“ã®å›ç­”ã¯ã„ã‹ãŒã§ã—ãŸã‹ï¼Ÿ")

        col1, col2, col3, col4, col5 = st.columns(5)

        satisfaction_scores = {}

        with col1:
            satisfaction_scores['overall'] = st.select_slider(
                "ç·åˆæº€è¶³åº¦", options=[1,2,3,4,5], value=3, key="overall_satisfaction"
            )

        with col2:
            satisfaction_scores['accuracy'] = st.select_slider(
                "å›ç­”ç²¾åº¦", options=[1,2,3,4,5], value=3, key="accuracy_satisfaction"
            )

        with col3:
            satisfaction_scores['speed'] = st.select_slider(
                "å¿œç­”é€Ÿåº¦", options=[1,2,3,4,5], value=3, key="speed_satisfaction"
            )

        with col4:
            satisfaction_scores['helpfulness'] = st.select_slider(
                "æœ‰ç”¨æ€§", options=[1,2,3,4,5], value=3, key="helpfulness_satisfaction"
            )

        # ãƒ•ãƒªãƒ¼ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
        positive_feedback = st.text_area(
            "è‰¯ã‹ã£ãŸç‚¹ã‚’ãŠèã‹ã›ãã ã•ã„",
            placeholder="ã“ã®å›ç­”ã§å½¹ã«ç«‹ã£ãŸéƒ¨åˆ†ã‚„è‰¯ã‹ã£ãŸç‚¹ãŒã‚ã‚Œã°æ•™ãˆã¦ãã ã•ã„"
        )

        improvement_feedback = st.text_area(
            "æ”¹å–„ææ¡ˆãŒã‚ã‚Œã°ãŠèã‹ã›ãã ã•ã„",
            placeholder="ã‚ˆã‚Šè‰¯ã„å›ç­”ã«ã™ã‚‹ãŸã‚ã®ã”ææ¡ˆãŒã‚ã‚Œã°æ•™ãˆã¦ãã ã•ã„"
        )

        if st.button("ğŸ“¤ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯é€ä¿¡"):
            feedback_data = {
                **satisfaction_scores,
                'positive_feedback': positive_feedback,
                'improvements': improvement_feedback
            }

            # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ä¿å­˜
            if save_user_feedback(st.session_state.get('last_conversation_id'), feedback_data):
                st.success("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’é€ä¿¡ã—ã¾ã—ãŸã€‚ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼")
                st.balloons()
            else:
                st.error("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®é€ä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸ")
```

#### 6.3.2 è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ 

**GitHub Actionsè‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—è¨­å®š**

`.github/workflows/data_backup.yml`ã‚’ä½œæˆï¼š

```yaml
name: ğŸ”„ Automated Data Backup & Sync

on:
  schedule:
    # æ¯æ—¥åˆå‰3æ™‚(JST)ã«å®Ÿè¡Œ
    - cron: '0 18 * * *'  # UTC 18:00 = JST 03:00
  workflow_dispatch:
    inputs:
      backup_type:
        description: 'ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®ç¨®é¡'
        required: true
        default: 'incremental'
        type: choice
        options:
        - incremental
        - full
        - emergency

jobs:
  automated_backup:
    runs-on: ubuntu-latest

    steps:
    - name: ğŸ“¥ ãƒªãƒã‚¸ãƒˆãƒªã‚’ãƒã‚§ãƒƒã‚¯ã‚¢ã‚¦ãƒˆ
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0

    - name: ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
      run: |
        echo "=== ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ç¢ºèª ==="
        if [ -d "data" ]; then
          find data -type f -name "*.db" -o -name "*.json" -o -name "*.csv" | head -20
          du -sh data/ || echo "ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚µã‚¤ã‚ºæ¸¬å®šä¸å¯"
        else
          echo "dataãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“"
          mkdir -p data
        fi

    - name: ğŸ”„ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
      run: |
        echo "=== ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ ==="

        # SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
        for db_file in data/*.db; do
          if [ -f "$db_file" ]; then
            echo "ãƒã‚§ãƒƒã‚¯ä¸­: $db_file"
            # SQLiteãƒ•ã‚¡ã‚¤ãƒ«ã®ç ´æãƒã‚§ãƒƒã‚¯ï¼ˆåŸºæœ¬çš„ãªç¢ºèªï¼‰
            if file "$db_file" | grep -q "SQLite"; then
              echo "âœ… $db_file ã¯æœ‰åŠ¹ãªSQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§ã™"
            else
              echo "âš ï¸ $db_file ã¯ç ´æã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™"
            fi
          fi
        done

    - name: ğŸ“‹ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
      run: |
        echo "=== ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ ==="

        backup_timestamp=$(date '+%Y-%m-%d %H:%M:%S UTC')
        backup_type="${{ github.event.inputs.backup_type || 'incremental' }}"

        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        cat > data/backup_metadata.json << EOF
        {
          "backup_timestamp": "$backup_timestamp",
          "backup_type": "$backup_type",
          "triggered_by": "${{ github.event_name }}",
          "repository": "${{ github.repository }}",
          "commit_sha": "${{ github.sha }}",
          "workflow_run_id": "${{ github.run_id }}",
          "data_summary": {
            "total_files": $(find data -type f | wc -l),
            "database_files": $(find data -name "*.db" | wc -l),
            "json_files": $(find data -name "*.json" | wc -l),
            "backup_files": $(find data -name "*backup*" | wc -l)
          }
        }
        EOF

        echo "ğŸ“„ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿:"
        cat data/backup_metadata.json

    - name: ğŸ§¹ å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
      run: |
        echo "=== å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ ==="

        # 30æ—¥ä»¥ä¸Šå¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        find data -name "*backup*" -type f -mtime +30 -delete 2>/dev/null || true

        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆ100ãƒ•ã‚¡ã‚¤ãƒ«ä»¥ä¸Šã§å¤ã„ã‚‚ã®ã‚’å‰Šé™¤ï¼‰
        log_count=$(find data -name "*.log" | wc -l)
        if [ "$log_count" -gt 100 ]; then
          find data -name "*.log" -type f -printf '%T@ %p\n' | sort -n | head -50 | cut -d' ' -f2- | xargs rm -f
          echo "å¤ã„ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ"
        fi

    - name: ğŸ“ å¤‰æ›´ã‚µãƒãƒªãƒ¼ç”Ÿæˆ
      run: |
        echo "=== å¤‰æ›´ã‚µãƒãƒªãƒ¼ç”Ÿæˆ ==="

        # Git statusç¢ºèª
        git status --porcelain

        # å¤‰æ›´ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if [ -n "$(git status --porcelain)" ]; then
          echo "ğŸ“Š å¤‰æ›´ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ"
          git add data/

          # ã‚³ãƒŸãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆ
          commit_message="ğŸ”„ è‡ªå‹•ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: $(date '+%Y-%m-%d %H:%M:%S')"

          if [ "${{ github.event.inputs.backup_type }}" = "emergency" ]; then
            commit_message="ğŸš¨ ç·Šæ€¥ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: $(date '+%Y-%m-%d %H:%M:%S')"
          fi

          echo "COMMIT_MESSAGE=$commit_message" >> $GITHUB_ENV
          echo "HAS_CHANGES=true" >> $GITHUB_ENV
        else
          echo "ğŸ“­ å¤‰æ›´ãªã— - ã‚³ãƒŸãƒƒãƒˆä¸è¦"
          echo "HAS_CHANGES=false" >> $GITHUB_ENV
        fi

    - name: ğŸš€ å¤‰æ›´ã‚’ã‚³ãƒŸãƒƒãƒˆãƒ»ãƒ—ãƒƒã‚·ãƒ¥
      if: env.HAS_CHANGES == 'true'
      run: |
        echo "=== Gitè¨­å®š ==="
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Actions Data Backup"

        echo "=== ã‚³ãƒŸãƒƒãƒˆå®Ÿè¡Œ ==="
        git commit -m "${{ env.COMMIT_MESSAGE }}"

        echo "=== ãƒ—ãƒƒã‚·ãƒ¥å®Ÿè¡Œ ==="
        git push

    - name: ğŸ“¬ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†é€šçŸ¥
      if: always()
      run: |
        echo "=== ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å‡¦ç†å®Œäº† ==="
        echo "å®Ÿè¡Œæ™‚åˆ»: $(date)"
        echo "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¿ã‚¤ãƒ—: ${{ github.event.inputs.backup_type || 'incremental' }}"
        echo "å¤‰æ›´ã‚ã‚Š: ${{ env.HAS_CHANGES || 'false' }}"
        echo "ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡ŒID: ${{ github.run_id }}"

        # å®Ÿè¡Œãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        echo "$(date '+%Y-%m-%d %H:%M:%S') - ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†" >> data/backup_execution.log
```

#### 6.3.3 ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ»åˆ†ææ©Ÿèƒ½

**ç®¡ç†ç”»é¢ã§ã®ãƒ‡ãƒ¼ã‚¿åˆ†ææ©Ÿèƒ½è¿½åŠ **

`pages/admin.py`ã«ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’è¿½åŠ ï¼š

```python
def render_data_analytics_section():
    """ãƒ‡ãƒ¼ã‚¿åˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°"""

    st.header("ğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ»ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆè¡¨ç¤º
    db = initialize_persistent_database()
    analytics = db.get_comprehensive_analytics()

    # 1. åŸºæœ¬çµ±è¨ˆè¡¨ç¤º
    st.subheader("ğŸ“ˆ åŸºæœ¬çµ±è¨ˆï¼ˆéå»30æ—¥ï¼‰")

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric(
            "ç·ä¼šè©±æ•°",
            analytics['basic_stats']['total_conversations'],
            help="éå»30æ—¥é–“ã®ç·ä¼šè©±æ•°"
        )

    with col2:
        st.metric(
            "ãƒ¦ãƒ‹ãƒ¼ã‚¯ã‚»ãƒƒã‚·ãƒ§ãƒ³",
            analytics['basic_stats']['unique_sessions'],
            help="éå»30æ—¥é–“ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°"
        )

    with col3:
        st.metric(
            "å¹³å‡æº€è¶³åº¦",
            f"{analytics['basic_stats']['avg_satisfaction']:.1f}/5.0",
            help="ãƒ¦ãƒ¼ã‚¶ãƒ¼æº€è¶³åº¦ã®å¹³å‡å€¤"
        )

    with col4:
        st.metric(
            "å¹³å‡å¿œç­”æ™‚é–“",
            f"{analytics['basic_stats']['avg_processing_time_ms']:.0f}ms",
            help="AIå¿œç­”ã®å¹³å‡å‡¦ç†æ™‚é–“"
        )

    # 2. ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½
    st.subheader("ğŸ“¤ ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")

    col1, col2 = st.columns(2)

    with col1:
        export_format = st.selectbox(
            "ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå½¢å¼",
            ["CSV", "JSON", "Excel"],
            help="ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã®å½¢å¼ã‚’é¸æŠ"
        )

    with col2:
        date_range = st.selectbox(
            "æœŸé–“",
            ["éå»7æ—¥", "éå»30æ—¥", "éå»90æ—¥", "å…¨æœŸé–“"],
            help="ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã®æœŸé–“ã‚’é¸æŠ"
        )

    if st.button("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Ÿè¡Œ"):
        with st.spinner("ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆä¸­..."):
            try:
                # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Ÿè¡Œ
                export_file = db.export_data_for_analysis(export_format.lower())

                if export_file:
                    st.success(f"âœ… ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†: {export_file}")

                    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³è¡¨ç¤º
                    with open(export_file, 'rb') as f:
                        st.download_button(
                            label="ğŸ“¥ ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=f.read(),
                            file_name=Path(export_file).name,
                            mime='application/octet-stream'
                        )
                else:
                    st.error("âŒ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ")

            except Exception as e:
                st.error(f"âŒ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")

    # 3. ãƒ‡ãƒ¼ã‚¿å‰Šé™¤ãƒ»ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—æ©Ÿèƒ½
    st.subheader("ğŸ§¹ ãƒ‡ãƒ¼ã‚¿ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹")

    with st.expander("âš ï¸ ä¸Šç´šè€…å‘ã‘ - ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"):
        st.warning(
            "ğŸš¨ **æ³¨æ„**: ã“ã®æ“ä½œã¯å…ƒã«æˆ»ã›ã¾ã›ã‚“ã€‚"
            "å¿…ãšäº‹å‰ã«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å–å¾—ã—ã¦ãã ã•ã„ã€‚"
        )

        cleanup_days = st.number_input(
            "å‰Šé™¤å¯¾è±¡ï¼ˆæŒ‡å®šæ—¥æ•°ã‚ˆã‚Šå¤ã„ãƒ‡ãƒ¼ã‚¿ï¼‰",
            min_value=30,
            max_value=365,
            value=90,
            help="æŒ‡å®šã—ãŸæ—¥æ•°ã‚ˆã‚Šå¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¾ã™"
        )

        if st.button("ğŸ—‘ï¸ å¤ã„ãƒ‡ãƒ¼ã‚¿å‰Šé™¤å®Ÿè¡Œ", type="secondary"):
            confirm = st.checkbox("å‰Šé™¤ã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ã‚’ç†è§£ã—ã¾ã—ãŸ")

            if confirm:
                # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Ÿè¡Œ
                deleted_count = db.cleanup_old_data(cleanup_days)
                st.success(f"âœ… {deleted_count}ä»¶ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
            else:
                st.warning("ç¢ºèªãƒã‚§ãƒƒã‚¯ã‚’å…¥ã‚Œã¦ãã ã•ã„")
```

### 6.4 ğŸ’¡ é‹ç”¨æ™‚ã®é‡è¦ãƒã‚¤ãƒ³ãƒˆ

#### 6.4.1 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

```python
# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æœ€é©åŒ–
PERFORMANCE_INDEXES = """
    -- é«˜é€Ÿæ¤œç´¢ç”¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    CREATE INDEX IF NOT EXISTS idx_conversation_session_time
    ON conversation_history(session_id, timestamp);

    CREATE INDEX IF NOT EXISTS idx_conversation_product_time
    ON conversation_history(product_name, timestamp);

    CREATE INDEX IF NOT EXISTS idx_feedback_conversation
    ON user_feedback_detailed(conversation_id);

    CREATE INDEX IF NOT EXISTS idx_sessions_start_time
    ON user_sessions(start_time);
"""
```

#### 6.4.2 ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ»ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼å¯¾ç­–

```python
# å€‹äººæƒ…å ±ä¿è­·è¨­å®š
PRIVACY_CONFIG = {
    "anonymize_ip": True,           # IPã‚¢ãƒ‰ãƒ¬ã‚¹ã®åŒ¿ååŒ–
    "hash_user_agents": True,       # User-Agentã®ãƒãƒƒã‚·ãƒ¥åŒ–
    "retention_period_days": 365,   # ãƒ‡ãƒ¼ã‚¿ä¿æŒæœŸé–“
    "auto_delete_old_data": True,   # å¤ã„ãƒ‡ãƒ¼ã‚¿ã®è‡ªå‹•å‰Šé™¤
    "encrypt_sensitive_data": True   # æ©Ÿå¯†ãƒ‡ãƒ¼ã‚¿ã®æš—å·åŒ–
}
```

    def save_chat_message(self, session_id, product_name, user_message,
                         bot_response, sources_used="", prompt_style=""):
        """ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿å­˜"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                INSERT INTO chat_history
                (timestamp, session_id, product_name, user_message,
                 bot_response, sources_used, prompt_style)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """, (
                datetime.now().isoformat(),
                session_id,
                product_name,
                user_message,
                bot_response,
                sources_used,
                prompt_style
            ))
            conn.commit()

    def get_chat_history(self, product_name, limit=100):
        """ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’å–å¾—"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute("""
                SELECT timestamp, user_message, bot_response, sources_used
                FROM chat_history
                WHERE product_name = ?
                ORDER BY timestamp DESC
                LIMIT ?
            """, (product_name, limit))
            return cursor.fetchall()

    def save_feedback(self, session_id, satisfaction, feedback_text=""):
        """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ä¿å­˜"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                INSERT INTO user_feedback (session_id, satisfaction, feedback_text)
                VALUES (?, ?, ?)
            """, (session_id, satisfaction, feedback_text))
            conn.commit()

    def get_statistics(self):
        """åˆ©ç”¨çµ±è¨ˆã‚’å–å¾—"""
        with sqlite3.connect(self.db_path) as conn:
            # ç·ãƒãƒ£ãƒƒãƒˆæ•°
            total_chats = conn.execute(
                "SELECT COUNT(*) FROM chat_history"
            ).fetchone()[0]

            # æº€è¶³åº¦çµ±è¨ˆ
            satisfaction_stats = conn.execute("""
                SELECT satisfaction, COUNT(*)
                FROM user_feedback
                GROUP BY satisfaction
            """).fetchall()

            return {
                "total_chats": total_chats,
                "satisfaction_stats": satisfaction_stats
            }

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
persistent_db = PersistentDatabase()
```

#### 6.1.2 ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç®¡ç†ã®æ›´æ–°

`utils/feedback_manager.py`ã‚’æ°¸ç¶šåŒ–å¯¾å¿œã«æ›´æ–°ï¼š

```python
# æ—¢å­˜ã®FeedbackManagerã‚¯ãƒ©ã‚¹ã«è¿½åŠ 
from config.database import persistent_db

def save_chat_message(self, product_name, user_message, bot_response,
                     sources_used, prompt_style):
    """æ°¸ç¶šåŒ–å¯¾å¿œãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¿å­˜"""
    session_id = self.get_session_id(product_name)

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
    persistent_db.save_chat_message(
        session_id=session_id,
        product_name=product_name,
        user_message=user_message,
        bot_response=bot_response,
        sources_used="; ".join(sources_used),
        prompt_style=prompt_style
    )

    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚‚ä¿å­˜ï¼ˆäº’æ›æ€§ã®ãŸã‚ï¼‰
    return super().save_chat_message(
        product_name, user_message, bot_response, sources_used, prompt_style
    )
```

### 6.2 ãƒ‡ãƒ¼ã‚¿å®¹é‡ç®¡ç†

```python
# config/data_management.py
class DataManager:
    """ãƒ‡ãƒ¼ã‚¿å®¹é‡ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        self.max_chat_records = 10000  # æœ€å¤§1ä¸‡ä»¶
        self.max_db_size_mb = 50       # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æœ€å¤§50MB

    def cleanup_old_chats(self, days_old=90):
        """å¤ã„ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’å‰Šé™¤"""
        cutoff_date = datetime.now() - timedelta(days=days_old)

        with sqlite3.connect("data/chatbot.db") as conn:
            conn.execute("""
                DELETE FROM chat_history
                WHERE timestamp < ?
            """, (cutoff_date.isoformat(),))
            conn.commit()

    def get_database_size(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚µã‚¤ã‚ºã‚’å–å¾—"""
        db_path = Path("data/chatbot.db")
        if db_path.exists():
            return db_path.stat().st_size / (1024 * 1024)  # MB
        return 0
```

### 3.1 ãƒ‡ãƒ—ãƒ­ã‚¤æ‰‹é †ï¼ˆ5åˆ†ï¼‰

1. **Streamlit Cloud**ã«ã‚¢ã‚¯ã‚»ã‚¹
   ```
   https://share.streamlit.io/
   ```

2. **GitHubé€£æº**
   - "New app" â†’ GitHubãƒªãƒã‚¸ãƒˆãƒªã‚’é¸æŠ
   - Main file: `app.py`
   - Branch: `main`

3. **Secretsè¨­å®š**
   - App settings â†’ Secrets
   - `.streamlit/secrets.toml`ã®å†…å®¹ã‚’ã‚³ãƒ”ãƒ¼

4. **ãƒ‡ãƒ—ãƒ­ã‚¤å®Ÿè¡Œ**
   - "Deploy!" ã‚¯ãƒªãƒƒã‚¯
   - è‡ªå‹•ãƒ“ãƒ«ãƒ‰é–‹å§‹ï¼ˆ2-3åˆ†ï¼‰

### 3.2 ã‚«ã‚¹ã‚¿ãƒ ãƒ‰ãƒ¡ã‚¤ãƒ³è¨­å®š

```bash
# Streamlit Cloud Proï¼ˆæœ‰æ–™ï¼‰ã§ã‚«ã‚¹ã‚¿ãƒ ãƒ‰ãƒ¡ã‚¤ãƒ³å¯èƒ½
# ç„¡æ–™ç‰ˆ: https://your-app-name.streamlit.app/
```

---

## 4. AWS ãƒ‡ãƒ—ãƒ­ã‚¤

### 4.1 EC2 ãƒ‡ãƒ—ãƒ­ã‚¤

**4.1.1 EC2ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ**
```bash
# Amazon Linux 2
# t3.mediumä»¥ä¸Šæ¨å¥¨ï¼ˆRAGå‡¦ç†ã®ãŸã‚ï¼‰
# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚°ãƒ«ãƒ¼ãƒ—: HTTP(80), HTTPS(443), SSH(22)
```

**4.1.2 ç’°å¢ƒæ§‹ç¯‰**
```bash
# Python 3.11ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
sudo yum update -y
sudo yum install -y python3.11 python3.11-pip git

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é…ç½®
git clone https://github.com/your-repo/wiki-chatbot.git
cd wiki-chatbot
pip3.11 install -r requirements.txt
```

**4.1.3 ç’°å¢ƒå¤‰æ•°è¨­å®š**
```bash
# /etc/environment ã«è¿½åŠ 
sudo nano /etc/environment

OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
GOOGLE_API_KEY=...
WEB_PASSWORD=secure-password
```

**4.1.4 è‡ªå‹•èµ·å‹•è¨­å®š**
```bash
# systemdã‚µãƒ¼ãƒ“ã‚¹ä½œæˆ
sudo nano /etc/systemd/system/wiki-chatbot.service

[Unit]
Description=Wiki Chatbot
After=network.target

[Service]
Type=simple
User=ec2-user
WorkingDirectory=/home/ec2-user/wiki-chatbot
ExecStart=/usr/local/bin/streamlit run app.py --server.port=8501 --server.address=0.0.0.0
Restart=always

[Install]
WantedBy=multi-user.target

# ã‚µãƒ¼ãƒ“ã‚¹æœ‰åŠ¹åŒ–
sudo systemctl enable wiki-chatbot
sudo systemctl start wiki-chatbot
```

### 4.2 ECS ãƒ‡ãƒ—ãƒ­ã‚¤

**Dockerfile**
```dockerfile
FROM python:3.11-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

EXPOSE 8501

HEALTHCHECK CMD curl --fail http://localhost:8501/_stcore/health

ENTRYPOINT ["streamlit", "run", "app.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

---

## 5. Google Cloud ãƒ‡ãƒ—ãƒ­ã‚¤

### 5.1 Cloud Run ãƒ‡ãƒ—ãƒ­ã‚¤

```bash
# 1. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®š
gcloud config set project YOUR_PROJECT_ID

# 2. Container Registryæœ‰åŠ¹åŒ–
gcloud services enable run.googleapis.com
gcloud services enable containerregistry.googleapis.com

# 3. ã‚³ãƒ³ãƒ†ãƒŠãƒ“ãƒ«ãƒ‰
gcloud builds submit --tag gcr.io/YOUR_PROJECT_ID/wiki-chatbot

# 4. Cloud Runãƒ‡ãƒ—ãƒ­ã‚¤
gcloud run deploy wiki-chatbot \
  --image gcr.io/YOUR_PROJECT_ID/wiki-chatbot \
  --platform managed \
  --region asia-northeast1 \
  --allow-unauthenticated \
  --set-env-vars OPENAI_API_KEY=sk-... \
  --set-env-vars WEB_PASSWORD=secure-password \
  --memory 2Gi \
  --cpu 1
```

---

## 6. Azure ãƒ‡ãƒ—ãƒ­ã‚¤

### 6.1 Container Instances

```bash
# 1. ãƒªã‚½ãƒ¼ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—ä½œæˆ
az group create --name wiki-chatbot-rg --location japaneast

# 2. Container Registryä½œæˆ
az acr create --resource-group wiki-chatbot-rg \
  --name wikichatbotacr --sku Basic

# 3. ã‚¤ãƒ¡ãƒ¼ã‚¸ãƒ—ãƒƒã‚·ãƒ¥
az acr build --registry wikichatbotacr \
  --image wiki-chatbot:latest .

# 4. Container Instance ãƒ‡ãƒ—ãƒ­ã‚¤
az container create \
  --resource-group wiki-chatbot-rg \
  --name wiki-chatbot-app \
  --image wikichatbotacr.azurecr.io/wiki-chatbot:latest \
  --dns-name-label wiki-chatbot-unique \
  --ports 8501 \
  --environment-variables \
    OPENAI_API_KEY=sk-... \
    WEB_PASSWORD=secure-password
```

---

## 7. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®š

### 7.1 èªè¨¼å¼·åŒ–

**ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰èªè¨¼**
```python
# config/web_settings.py ã§è¨­å®š
WEB_PASSWORD = "complex-password-123"
MAX_LOGIN_ATTEMPTS = 3
```

**ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†**
```python
SESSION_TIMEOUT_HOURS = 8  # 8æ™‚é–“ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
MAX_QUERIES_PER_SESSION = 100  # ã‚»ãƒƒã‚·ãƒ§ãƒ³æ¯ã®ä¸Šé™
```

### 7.2 HTTPSåŒ–

**Streamlit Cloud**: è‡ªå‹•ã§HTTPS

**AWS**: Application Load Balancer + SSLè¨¼æ˜æ›¸

**GCP**: Cloud Load Balancing + SSLè¨¼æ˜æ›¸

### 7.3 ãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«è¨­å®š

```bash
# AWS Security Group
# ã‚¤ãƒ³ãƒã‚¦ãƒ³ãƒ‰: HTTPS(443), HTTP(80)ã®ã¿
# ã‚¢ã‚¦ãƒˆãƒã‚¦ãƒ³ãƒ‰: HTTPS(443)ã®ã¿ï¼ˆAPIé€šä¿¡ç”¨ï¼‰

# GCP Firewall Rules
gcloud compute firewall-rules create allow-wiki-chatbot \
  --allow tcp:8501 \
  --source-ranges 0.0.0.0/0 \
  --description "Allow Wiki Chatbot access"
```

---

## 8. RAGãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç§»ç®¡

### 8.1 ãƒ­ãƒ¼ã‚«ãƒ«ã‹ã‚‰æœ¬ç•ªç’°å¢ƒã¸

**8.1.1 ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç§»ç®¡**
```bash
# ãƒ­ãƒ¼ã‚«ãƒ«ã®data/ã‚’æœ¬ç•ªç’°å¢ƒã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
# Streamlit Cloud: GitHubçµŒç”±ã§è‡ªå‹•åŒæœŸ
# AWS: S3ãƒã‚±ãƒƒãƒˆçµŒç”±ã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
# GCP: Cloud StorageçµŒç”±ã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
```

**8.1.2 ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®å†æ§‹ç¯‰**
```bash
# æœ¬ç•ªç’°å¢ƒã§åˆå›èµ·å‹•æ™‚ã«è‡ªå‹•å®Ÿè¡Œã•ã‚Œã‚‹
# ã¾ãŸã¯ç®¡ç†ç”»é¢ã‹ã‚‰æ‰‹å‹•ã§ã€Œã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰ã€å®Ÿè¡Œ
```

### 8.2 æ°¸ç¶šåŒ–ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸è¨­å®š

**AWS EFS ãƒã‚¦ãƒ³ãƒˆ**
```bash
# EFSä½œæˆãƒ»ãƒã‚¦ãƒ³ãƒˆã—ã¦data/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ°¸ç¶šåŒ–
sudo mount -t efs fs-12345:/ /home/ec2-user/wiki-chatbot/data/
```

**GCP Persistent Disk**
```yaml
# Cloud Runç”¨ã®æ°¸ç¶šåŒ–è¨­å®š
apiVersion: run.googleapis.com/v1
kind: Service
spec:
  template:
    spec:
      volumes:
      - name: data-volume
        csi:
          driver: pd.csi.storage.gke.io
          volumeAttributes:
            type: pd-standard
```

---

## 9. ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### 9.1 ã‚ˆãã‚ã‚‹å•é¡Œ

**âŒ ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼**
```bash
# è§£æ±ºç­–: ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚µã‚¤ã‚ºã‚¢ãƒƒãƒ—
# AWS: t3.medium â†’ t3.large
# GCP: --memory 2Gi â†’ --memory 4Gi
```

**âŒ API Key ã‚¨ãƒ©ãƒ¼**
```bash
# è§£æ±ºç­–: ç’°å¢ƒå¤‰æ•°ã®ç¢ºèª
# Streamlit Cloud: Secretsè¨­å®šã‚’å†ç¢ºèª
# AWS/GCP: ç’°å¢ƒå¤‰æ•°ã®è¨­å®šã‚’ç¢ºèª
```

**âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼**
```bash
# è§£æ±ºç­–: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰åˆ¶é™ã®èª¿æ•´
# streamlit config set server.maxUploadSize 200
```

### 9.2 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

**ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­å®š**
```python
# config/settings.py
ENABLE_CACHE = True
CACHE_TTL = 3600  # 1æ™‚é–“
```

**åŒæ™‚æ¥ç¶šæ•°åˆ¶é™**
```python
# config/web_settings.py
MAX_CONCURRENT_USERS = 10
```

### 9.3 ãƒ­ã‚°ãƒ»ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°

**åŸºæœ¬ãƒ­ã‚°è¨­å®š**
```python
# utils/logger.py
LOG_LEVEL = "INFO"
LOG_FORMAT = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
```

**å¤–éƒ¨ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°**
- AWS: CloudWatch
- GCP: Cloud Monitoring
- Azure: Application Insights

---

## ğŸš€ ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå®Œäº†ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### äº‹å‰æº–å‚™
- [ ] API Keyå–å¾—ãƒ»è¨­å®šå®Œäº†
- [ ] GitHubãƒªãƒã‚¸ãƒˆãƒªpushå®Œäº†
- [ ] requirements.txtæ›´æ–°å®Œäº†

### ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£
- [ ] WEB_PASSWORDè¨­å®šå®Œäº†
- [ ] HTTPSæœ‰åŠ¹åŒ–å®Œäº†
- [ ] ãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«è¨­å®šå®Œäº†

### æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
- [ ] ãƒ­ã‚°ã‚¤ãƒ³æ©Ÿèƒ½å‹•ä½œç¢ºèª
- [ ] ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½å‹•ä½œç¢ºèª
- [ ] ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‹•ä½œç¢ºèª
- [ ] ç®¡ç†ç”»é¢ã‚¢ã‚¯ã‚»ã‚¹ç¢ºèª

### é‹ç”¨æº–å‚™
- [ ] ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°è¨­å®šå®Œäº†
- [ ] ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—è¨­å®šå®Œäº†
- [ ] ã‚¢ã‚¯ã‚»ã‚¹ãƒ­ã‚°ç¢ºèªæ–¹æ³•æ•´å‚™å®Œäº†

---

**æœ€çµ‚æ›´æ–°**: 2025å¹´9æœˆ15æ—¥
**å¯¾å¿œãƒãƒ¼ã‚¸ãƒ§ãƒ³**: Wiki Chatbot v4.0
**æ¨å¥¨ãƒ‡ãƒ—ãƒ­ã‚¤**: Streamlit Cloudï¼ˆå°è¦æ¨¡ï¼‰ã€AWS/GCPï¼ˆæœ¬æ ¼é‹ç”¨ï¼‰